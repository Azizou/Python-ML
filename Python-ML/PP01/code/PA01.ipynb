{
 "metadata": {
  "name": "PA01"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": [
      "##CMSC726 Programming Assignment 1: Decision Trees, K-NN and inductive bias", 
      "", 
      "In this programming assignment you will implement the Decision Tree method and experiment with it and ", 
      "K-nearest neighbors. You will use k-nn code and the spam dataset from the knn ", 
      "[practical session of September 7.](http://cbcb.umd.edu/~hcorrada/PML/src/knn.ipynb) Questions are shown", 
      "<font color=#ff3300>in this color.</font> Please address everything marked TODO below.", 
      "", 
      "Start early, and ask questions often."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Part I: The decision tree algorithm", 
      "", 
      "<font color=#ff3300>Implement the decision tree algorithm as presented in CIML, including treedepth as a hyper-parameter. Recall that", 
      "features in the spam dataset are continuous, so you need to figure out how to deal with those. Please disscuss below how you", 
      "did that. Also, Insert the code here, e.g.:</font>"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "TODO: Discuss how you dealt with continues features", 
      "", 
      "ANSWER: At first I thought that it would be a good idea to split each feature at its median value. Afterwards, I'd compute the gain of each feature", 
      "and sort the features according to their gain in descending order. However, this is not a good idea. There is not a single good reason for which the ", 
      "optimal gain for each feature has to be found, e.g., in the median, the mean, or the $k_{th}$ percentile of the feature values. It is pretty much", 
      "guaranteed that every feature will be different in that respect. So the question arises of how to compute the optimal split point for each feature.", 
      "", 
      "I ended up trusting an algorithm that finds the optimal split point of every feature by considering example pairs that differ in their feature", 
      "values and labels. In effect, for every feature, this algorithm sorts the examples according to feature value, then considers every adjacent feature pair", 
      "$e_1, e_2$. If a feature pair differs in both feature value and label, then the value of the feature at example $e_2$ is a *candidate split point*  for the feature", 
      "in its entirety.", 
      "", 
      "In pseudocode:", 
      "", 
      "    for every feature f", 
      "        sort training examples according to their values at f", 
      "        for every adjacent examples (e1, e2)", 
      "            if(e1.f != e2.f && e1.label != e2.label)", 
      "                score_of_e2 =  score for examples above e2.f + score of examples below e2.f", 
      "                if score_of_e2 > maximum_score_computed", 
      "                    maximum_score_computed = score_of_e2", 
      "                    best_split_point = e2", 
      "                end if", 
      "             end if", 
      "         end for", 
      "         best_split_point_in_feature = best_split_point", 
      "         best_split_point_score = maximum_score_computed"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "TODO: add source code"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "<pre><code>", 
      "'''", 
      "Created on Sep 17, 2012", 
      "", 
      "@author: jason", 
      "'''", 
      "", 
      "from __future__ import division             # used to receive accurate floating-point quotients when dividing integers/longs", 
      "import numpy as np", 
      "import pickle as pk", 
      "import pandas as pd", 
      "import copy", 
      "import util", 
      "import gc", 
      "import mlExceptions as mlex", 
      "from mlExceptions import LogicalError", 
      "", 
      "class Node:", 
      "    ", 
      "    '''", 
      "    This class represents both the decision tree's inner and leaf nodes.", 
      "    Leaf nodes are discerned by the \"isLeaf\" boolean variable and are also", 
      "    labeled with the prediction (\"label\") variable for that particular path", 
      "    of the decision tree. They are connected to their children by Node pointers", 
      "    \"left\" and \"right\", which are null by default and remain such for leaf nodes.", 
      "    ", 
      "    '''", 
      "    left, right = None, None", 
      "    ", 
      "    def __init__(self, feature, split_point, left = None, ", 
      "                 right = None, isLeaf = False, label = None ):", 
      "        '''", 
      "         Constructor", 
      "        '''", 
      "        self.feature = feature                           # feature splitted at (only makes sense for inner nodes)", 
      "        self.split_point = split_point                   # split point for feature (only makes sense for inner nodes)", 
      "        self.isLeaf = isLeaf                             # boolean flag to indicate a leaf node", 
      "        self.label = label                               # label of example (only makes sense for leaf nodes)", 
      "        self.left = left                                 # pointers to left and right children (null for leaf nodes)", 
      "        self.right = right", 
      "        ", 
      "class DecisionTree: ", 
      "    ", 
      "    '''", 
      "    The DecisionTree class is the implementation of the Decision Tree classifier. Included", 
      "    are private methods for computation of the optimal feature at each step, creation of inner", 
      "    and leaf nodes, as well as public methods for training, tuning and testing the classifier.", 
      "    ", 
      "    The decision tree represented by this class is a shallow decision tree of depth \"depth\" and ", 
      "    has been extended to use both score and information gain to estimate the split point quality.", 
      "    ", 
      "    The \"root\" Node object represents the root of the tree. It is initialized to None by the", 
      "    constructor of the class.", 
      "    ", 
      "    The two most interesting methods in this class are:", 
      "        1) __sortFeatures__ : Sorting of the dataset's features according to score or information gained. This", 
      "            method implements the algorithm described on \"PA01.ipynb\".", 
      "        2) __trainRec__ : Implementation of the decision tree training algorithm, as described on CIML.", 
      "        ", 
      "    '''", 
      "    def __init__(self, dataset, depth = 5, useInfoGain = False):", 
      "        ", 
      "        '''", 
      "        Description: Constructor.", 
      "        ", 
      "        The constructor only checks to see whether the depth parameter is above zero. We follow a lazy approach with", 
      "        respect to the dataset being empty or not, by making this check only if the user decides to train one particular", 
      "        decision tree object on the data.", 
      "        ", 
      "        Arguments: ", 
      "            dataset: pandas.DataFrame. The training dataset.", 
      "            depth: The maximum depth that the decision tree is allowed to reach. Default 5.", 
      "            useInfoGain: Boolean flag that states whether the user wants the split point quality to be measured", 
      "                in terms of Information Gain, as opposed to the default of node \"score\" (majority vote of splitted labels)", 
      "        '''", 
      "        ", 
      "        if depth <= 0 or not isinstance(depth, (int, long)):", 
      "            raise mlex.LogicalError(\"Depth parameter has to be a positive integer\")", 
      "        self.dataset = dataset", 
      "        self.depth = depth ", 
      "        self.useInfoGain = useInfoGain", 
      "        self.root = None", 
      "              ", 
      "              ", 
      "    def __str__(self):", 
      "        ", 
      "        '''", 
      "        Description: Stringifying method.  Converts the classifier to a string representation.", 
      "        Arguments: None", 
      "        Return value: A string, presumably with some data about this object.", 
      "        '''", 
      "        return 'A decision tree classifier of depth ' + self.depth", 
      "    ", 
      "               ", 
      "    def __selectFeature__(self, trainingData, features):", 
      "    ", 
      "        '''", 
      "        Description: Select the best feature found by self.__sortFeatures__", 
      "        ", 
      "        Arguments:", 
      "            trainingData: pandas.DataFrame. The training data available", 
      "            at the current level of the tree.", 
      "            features: a list of features to select from", 
      "        ", 
      "        Return value:", 
      "        A tuple (feature, split_point), where feature is the highest", 
      "        scoring feature on trainingData, and split_point is the", 
      "        split point which yielded that score.", 
      "        '''", 
      "         ", 
      "        # Just run self.__sortFeatures__ and then pick the ", 
      "        # first value in the returned list.", 
      "            ", 
      "        return self.__sortFeatures__(trainingData, features)[0]", 
      "    ", 
      "    def __sortFeatures__(self, trainingData, features):", 
      "    ", 
      "        '''", 
      "        Description: Similar to selectFeature, ", 
      "        only difference being that the features are", 
      "        stored in a list alongside their scores, and then ", 
      "        the list is sorted according to the scores. ", 
      "    ", 
      "        ", 
      "        Arguments:", 
      "            trainingData: pandas.DataFrame. The training data available", 
      "            at the current level of the tree.", 
      "            features: a list of features to sort in descending score order", 
      "            useInfoGain: a flag, by default False, which indicates whether information gain", 
      "                is the default split point quality measure (as opposed to the default of score)", 
      "        ", 
      "        Return value:", 
      "        A sorted list of tuples (feature, split_point). ", 
      "        '''", 
      "        ", 
      "        featureList = []                                        # the tuple list that we will return ", 
      "        for featureName in features:                            # loop through all features", 
      "            if featureName == 'spam':                           # label not a feature!", 
      "                continue", 
      "            bestFeatureSplit = None                             # initialize best split for this feature", 
      "            bestFeatureSplitScore = 0", 
      "            tempCopy = copy.deepcopy(trainingData[featureName]) # worried about sorting an argument in place", 
      "            tempCopy.sort()", 
      "            tempCopy = tempCopy[::-1].dropna()                  # I prefer descending order and I don't consider null values", 
      "            for i in range(tempCopy.index.size):                # loop through all examples in pairs", 
      "                if i == tempCopy.index.size -1:                 # avoid memory leak when encountering last example", 
      "                    break                  ", 
      "                        ", 
      "                # Important: Note the difference between", 
      "                # indexing the index and indexing the data", 
      "                             ", 
      "                exampleIndex1 = tempCopy.index[i]", 
      "                exampleIndex2 = tempCopy.index[i + 1]           # retrieve the indices of the two examples", 
      "                example1 = trainingData.ix[exampleIndex1, :]    # and the two examples themselves", 
      "                example2 = trainingData.ix[exampleIndex2, :]", 
      "        ", 
      "                # if the two adjacent examples differ in BOTH label", 
      "                # and feature value, calculate the score for the two sub-datasets", 
      "                # If you need to use information gain, add \"True\" as the second argument", 
      "                # to self.__calculateScore__.", 
      "                ", 
      "                if(example1['spam'] != example2['spam'] and ", 
      "                   example1[featureName] != example2[featureName]):", 
      "                    if self.useInfoGain == False:", 
      "                        ", 
      "                        # Use score for current node ", 
      "                        ", 
      "                        scoreLarger = self.__calculateScore__(trainingData[trainingData[featureName] >= ", 
      "                                                                  example2[featureName]])", 
      "                        scoreSmaller = self.__calculateScore__(trainingData[trainingData[featureName] < ", 
      "                                                                  example2[featureName]])", 
      "                        totalScore = scoreLarger + scoreSmaller", 
      "                    else:", 
      "                        ", 
      "                        # Use Information Gain for current node", 
      "            ", 
      "                        # First, compute cardinalities to weight info gain appropriately", 
      "                        ", 
      "                        cardinalityLarger = trainingData[trainingData[featureName] >= example2[featureName]].shape[0]", 
      "                        cardinalitySmaller = trainingData[trainingData[featureName] < example2[featureName]].shape[0]", 
      "                        cardinalityCurrent = trainingData.shape[0]", 
      "                        fractionLarger = cardinalityLarger / cardinalityCurrent", 
      "                        fractionSmaller = cardinalitySmaller / cardinalityCurrent", 
      "                        # Second, compute all entropies", 
      "                        ", 
      "                        currentEntropy = self.__calculateEntropy__(trainingData)", 
      "                        entropyLarger =  self.__calculateEntropy__(trainingData[trainingData[featureName] >= example2[featureName]])", 
      "                        entropySmaller = self.__calculateEntropy__(trainingData[trainingData[featureName] < example2[featureName]])", 
      "                        ", 
      "                        # Third, compute information gain based on both entropies and cardinalities", 
      "                        ", 
      "                        totalScore = currentEntropy - (fractionLarger* entropyLarger + fractionSmaller* entropySmaller)", 
      "                                                ", 
      "                    if(totalScore > bestFeatureSplitScore):", 
      "                        bestFeatureSplitScore = totalScore      # update best split score", 
      "                        bestFeatureSplit = example2[featureName]", 
      "                    ", 
      "            # end of for loop that scans through examples", 
      "            # we now have data that helps us see whether we improved upon", 
      "            # our already existing \"best\" feature", 
      "            ", 
      "            featureList.append((featureName, bestFeatureSplit, bestFeatureSplitScore))", 
      "        ", 
      "        # end of for loop that scans through features", 
      "        ", 
      "        return sorted(featureList, key=lambda data: data[2])[::-1]", 
      "    ", 
      "    # end of method    ", 
      "    ", 
      "    def __calculateScore__(self, dataset):", 
      "    ", 
      "        '''", 
      "        Description: Given a continuous feature vector (column)", 
      "        in the data and a split point, calculate the quality of", 
      "        the splitting. Metric used: score (majority vote of labels on", 
      "        either side of the splitting       ", 
      "        Arguments: ", 
      "            dataset: pandas.DataFrame        ", 
      "        Return value: The score of the feature ", 
      "        '''", 
      "        ", 
      "        if dataset.shape[0] == 0:                                          # If there are no rows to calculate a score from, return a score of zero", 
      "            return 0       ", 
      "", 
      "        if 1 in dataset.groupby('spam').shape.keys():", 
      "            positiveExampleCount = dataset.groupby('spam').shape[1][0]", 
      "        else:", 
      "            positiveExampleCount = 0", 
      "        if -1 in dataset.groupby('spam').shape.keys():", 
      "            negativeExampleCount = dataset.groupby('spam').shape[-1][0]", 
      "        else:", 
      "            negativeExampleCount = 0 ", 
      "        return max([positiveExampleCount, negativeExampleCount])       # python's default max faster than numpy.max for simple lists ", 
      "        ", 
      "            ", 
      "    def __calculateEntropy__(self, dataset):", 
      "        ", 
      "        '''", 
      "        Description: Calculate the entropy of a given dataset. ", 
      "        Arguments: ", 
      "            dataset: pandas.DataFrame", 
      "        Return value: the entropy of the dataset (float)", 
      "        '''", 
      "        if dataset.shape[0] == 0:", 
      "            # raise mlex.DatasetError(\"Cannot compute the entropy of an empty dataset.\")", 
      "            return 0                                                    # TODO: check whether this is correct", 
      "        if 1 in dataset.groupby('spam').shape.keys():", 
      "                positiveExampleCount = dataset.groupby('spam').shape[1][0]", 
      "        else:", 
      "                positiveExampleCount = 0", 
      "        if -1 in dataset.groupby('spam').shape.keys():", 
      "                negativeExampleCount = dataset.groupby('spam').shape[-1][0]", 
      "        else:", 
      "                negativeExampleCount = 0", 
      "        ", 
      "        positivesFraction = positiveExampleCount / dataset.shape[0]     # division library will take care of quotients", 
      "        negativesFraction = negativeExampleCount / dataset.shape[0]", 
      "        return -positivesFraction * np.log2(positivesFraction) -negativesFraction* np.log2(negativesFraction)", 
      "    ", 
      "    def train(self):", 
      "        ", 
      "        '''", 
      "        Description: Train the decision tree on the dataset provided.", 
      "            Merely a wrapper for the private method __trainRec__, which implements", 
      "            the recursive decision tree training algorithm outlined in CIML.", 
      "            Training only takes place if the dataset is not empty.", 
      "        Arguments: None", 
      "        Return value: None", 
      "        '''", 
      "        if self.dataset.shape[0] > 0:", 
      "            allFeatures = self.dataset.columns[0: self.dataset.columns.size -1]", 
      "            self.root = self.__trainRec__(self.dataset, allFeatures.tolist(), self.depth, 1)", 
      "        else:", 
      "            print \"No training data provided.\"", 
      "            return", 
      "            ", 
      "    def __trainRec__(self, dataset, features, depth, currentDepth): # Not to be confused with train wrecks.", 
      "        ", 
      "        '''", 
      "        Description: Execute the decision tree training algorithm ", 
      "            as described on CIML. Recursive method.", 
      "        ", 
      "        Arguments:", 
      "            dataset: the portion of the dataset available at the current tree node.", 
      "            features: a list of features to split at", 
      "            depth: the maximun depth of the (shallow) decision tree", 
      "            ", 
      "        Return value: Node", 
      "        '''", 
      "        ", 
      "        # The first thing that we need to do is ensure that the dataset is not empty. At this point,", 
      "        # this can only occur if the parent node made a perfect split and we just happen to be on the", 
      "        # losers' part of it. In this case, the caller itself has to be turned into a leaf node, whose ", 
      "        # label is the label corresponding to the path other than the one followed to reach the present", 
      "        # stack frame.", 
      "        ", 
      "        if dataset.shape[0] == 0:", 
      "            raise mlex.DatasetError(\"Cannot split an empty dataset\")", 
      "        ", 
      "        # If you had to make a prediction now, what would it be?", 
      "        ", 
      "        label = self.__majorityLabel__(dataset)", 
      "     ", 
      "        # Termination conditions of the training algorithm:", 
      "        #     1) no more features to examine", 
      "        #     2) Data is completely unambiguous, so you don't need to split any further", 
      "        #     3) Maximum depth of decision tree reached: not allowed to split any further.", 
      "        #     4) The dataset is empty because the parent splitting provided us with no data whatsoever", 
      "        #        (see exception above for more).", 
      "        ", 
      "        if features == [] or self.__dataUnambiguous__(dataset) or currentDepth == depth: ", 
      "            return self.__addNode__(None, None, None, None, True, label)    # no features, split point and children nodes in a leaf node", 
      "        ", 
      "        # Run feature selection algorithm on the current dataset and feature vector", 
      "        ", 
      "        (bestFeature, splitPoint, splitScore) = self.__selectFeature__(dataset, features) # We don't really use splitScore", 
      "        ", 
      "        # split data based on feature", 
      "        ", 
      "        positiveData = dataset[dataset[bestFeature] >= splitPoint]  ", 
      "        negativeData = dataset[dataset[bestFeature] < splitPoint]", 
      "        ", 
      "        # Remove the feature we just splitted on. ", 
      "                          ", 
      "        featureCopy = copy.deepcopy(features)", 
      "        featureCopy.remove(bestFeature)", 
      "        ", 
      "        # Recursive call for both 'positive' and 'negative' splits. ", 
      "        ", 
      "        try:", 
      "            left_child = self.__trainRec__(negativeData, featureCopy, depth, currentDepth + 1)", 
      "        except mlex.DatasetError: ", 
      "            ", 
      "            # The node itself is redundant and can be deleted. Its positive leaf node child takes its place.", 
      "            ", 
      "            return self.__addNode__(None, None, None, None, True, 1)", 
      "            ", 
      "        try:", 
      "            right_child = self.__trainRec__(positiveData, featureCopy, depth, currentDepth + 1)", 
      "        except mlex.DatasetError:", 
      "            ", 
      "            # Again, this node is redundant, so we replace it with its negative leaf node.", 
      "        ", 
      "            return self.__addNode__(None,  None, None, None, True, -1)", 
      "        ", 
      "        # creation and return of the decision tree node", 
      "        ", 
      "        return self.__addNode__(bestFeature, splitPoint, left_child, right_child)", 
      "    ", 
      "        # end of method", 
      "        ", 
      "    def __addNode__(self, feature, split_point, left_child, right_child, isLeaf = False, label=None):", 
      "        ", 
      "        '''", 
      "        Description: Create and return a new node in the decision tree. The node", 
      "        can be either an inner (splitter) node or a leaf node.", 
      "        ", 
      "        Arguments: ", 
      "            feature: the feature represented by the node (only makes sense for splitter nodes)", 
      "            split_point: the value at which the feature is splitted", 
      "            isLeaf: optional boolean flag indicating whether the node is a leaf node", 
      "            label: optional labeling of the (leaf) node", 
      "            ", 
      "        Returns: Node", 
      "        '''", 
      "        return Node(feature, split_point, left_child, right_child, isLeaf, label)", 
      "    ", 
      "    def __majorityLabel__(self, dataset):", 
      "        ", 
      "        '''", 
      "        Description: Return the majority label of a given dataset", 
      "        Arguments:", 
      "            dataset: pandas.DataFrame", 
      "        Returns: An integer representing the majority label of dataset.", 
      "        '''", 
      "        ", 
      "        # If the caller provides an empty dataset, throw an exception", 
      "        ", 
      "        if dataset.shape[0] == 0:", 
      "            raise mlex.DatasetError(\"Cannot compute majority label from an empty dataset.\")", 
      "        ", 
      "        # Calculate and return majority label", 
      "        ", 
      "        if 1 in dataset.groupby('spam').shape.keys():", 
      "            positiveLabelCount = dataset.groupby('spam').shape[1][0]", 
      "        else:", 
      "            positiveLabelCount = 0", 
      "        if -1 in dataset.groupby('spam').shape.keys():", 
      "            negativeLabelCount = dataset.groupby('spam').shape[-1][0]", 
      "        else:", 
      "            negativeLabelCount = 0", 
      "        if positiveLabelCount !=negativeLabelCount:", 
      "            return np.sign(positiveLabelCount - negativeLabelCount) ", 
      "        else: ", 
      "            return 2 * np.random.randint(0, 2) - 1                          # flip a coin if classes have equal count", 
      "                 ", 
      "                     ", 
      "    ", 
      "    def __dataUnambiguous__(self, dataset):", 
      "        ", 
      "        '''", 
      "        Description: Estimate whether the provided data is unambiguously labeled, i.e has ", 
      "            positive or negative labels only.", 
      "        Arguments:", 
      "            dataset: pandas.DataFrame", 
      "        Returns: True if data unambiguous, False otherwise.", 
      "        '''", 
      "        # If the caller provides an empty dataset, throw an exception.", 
      "        ", 
      "        if dataset.shape[0] == 0:", 
      "            raise mlex.DatasetError(\"Cannot estimate whether an empty dataset is unambiguous\")", 
      "        ", 
      "        # Dataset is unambiguous if either label is absent.", 
      "        ", 
      "        return 1 not in dataset.groupby('spam').shape.keys() or -1 not in dataset.groupby('spam').shape.keys()", 
      "    ", 
      "    ", 
      "    def classifyWithAllDepths(self, testPoints):", 
      "        ", 
      "        '''", 
      "        Description: Classify a set of testing examples using all the different trees that were", 
      "                trained with different depths during tuning. Useful for understanding the relationship", 
      "                between development (tuning) error and generalization (testing) error. If no tuning", 
      "                has taken place, this method informs the user and falls back to self.classify.", 
      "        Arguments: testPoints: pandas.DataFrame", 
      "        Return Value: None, but plenty of printings.", 
      "        '''", 
      "        ", 
      "        if testPoints.shape[0] == 0:", 
      "            raise LogicalError(\"Cannot classify an empty dataset.\")", 
      "        testPointLabels = testPoints['spam'].values", 
      "        self.tests = []                                   # keep track of test data, the same way you do with tune data", 
      "        if self.tunings == None:", 
      "            print \"Dataset hasn't been tuned, performing classification with default depth of \" + str(self.depth) + \" instead...\"", 
      "            classifications = self.classify(testPoints)", 
      "            testingError = np.mean ( (testPointLabels * classifications) < 0)", 
      "            print \"Testing error of decision tree is: \" + str(testingError)", 
      "            self.tests.append((self.depth, testingError))", 
      "            return ", 
      "        else:", 
      "            tempTreeStore = self.root     # Hold the current tree somewhere, because we will be changing the root pointer a lot. ", 
      "            for tuningData in self.tunings:", 
      "                print \"Classifying with depth: \" + str(tuningData[0]) + \".\"", 
      "                print \"For this depth, the tuning error was: \" + str(tuningData[1]) + \".\"", 
      "                self.root = tuningData[2]", 
      "                classifications = self.classify(testPoints)", 
      "                testingError = np.mean ( (testPointLabels * classifications) < 0)", 
      "                print \"Testing error of this decision tree is: \" + str(testingError)", 
      "                self.tests.append((tuningData[0], testingError))", 
      "            self.root = tempTreeStore", 
      "        print \"Estimated training error with all different depths.\"", 
      "        ", 
      "    def classify(self, testPoints):", 
      "        ", 
      "        '''", 
      "        Description: Classify a set of testing examples using the trained decision tree.", 
      "            A wrapper for the recursive function self.__classifyRec__, which implements the CIML algorithm.", 
      "        Arguments: ", 
      "            testPoints: pandas.DataFrame", 
      "        Returns:", 
      "            The classification of each test point (1 for spam and -1 for not spam)", 
      "        '''", 
      "        if testPoints.shape[0] == 0:", 
      "            print \"Please provide an example to test\"", 
      "            return None", 
      "        elif self.root == None:", 
      "            print \"Decision tree hasn't been trained on data.\" # I could offer to flip a coin for each testing example,", 
      "            return None                                        # but I thought it wasn't worth the effort", 
      "        else:                                      ", 
      "            classifications = []", 
      "            for testPointIndex in testPoints.index:", 
      "                testPoint = testPoints.ix[testPointIndex]", 
      "                classifications.append(self.__classifyRec__(self.root, testPoint))", 
      "            return classifications", 
      "        ", 
      "    def __classifyRec__(self, node, testPoint):", 
      "        ", 
      "        '''", 
      "        Description: Classify ONE testing example using the recursive algorithm outlined in CIML.", 
      "        Arguments: ", 
      "            tree: pandas.Series", 
      "        Return value: (after recursion) Classification of test point (1 for spam, -1 otherwise)", 
      "        '''", 
      "        if node.isLeaf == True:", 
      "            return node.label", 
      "        else:", 
      "            if testPoint[node.feature] < node.split_point:", 
      "                return self.__classifyRec__(node.left, testPoint)", 
      "            else:", 
      "                return self.__classifyRec__(node.right, testPoint)", 
      "            ", 
      "            ", 
      "    def dump(self, filePath):", 
      "        ", 
      "        \"\"\"", 
      "        Description: store the current object to a file. Stolen verbatim from project description. Pickle library used.", 
      "        Arguments:", 
      "            filePath: String representing the path to the output file.", 
      "        Return value: None", 
      "", 
      "        \"\"\"", 
      "        try:", 
      "            fp = open(filePath,'wb')", 
      "            pk.dump(self, fp)", 
      "            fp.close()", 
      "        except Exception as e:", 
      "            'Pickling failed for object ' + str(self) + ' on file ' + file + ' Exception: ' + e.message", 
      "            ", 
      "    ", 
      "    def tune(self, tuningSet, lowerDepthBound = 4, higherDepthBound = 20):", 
      "        ", 
      "        '''", 
      "        Description: tune the decision tree by measuring generalization error for various values of depth d.", 
      "            By default the values checked are between 4 and 20 inclusive.", 
      "        Arguments: ", 
      "            tuningSet: pandas.DataFrame. Set of examples to measure generalization error from.", 
      "            lowerDepthBound: Integer representing the lowest decision tree depth to use for tuning.", 
      "            higherDepthBound: Integer representing the lowest decision tree depth to use for tuning.", 
      "        Return Value: None", 
      "        '''", 
      "        ", 
      "        # Some argument checks first. We prefer to raise exceptions wherever the documentation of a method", 
      "        # explicitly states that the return value is None, so as to not expect of the caller to check an", 
      "        # output that is not expected to be present.", 
      "        ", 
      "        if lowerDepthBound > higherDepthBound:", 
      "            print \"Switching your arguments for lower and higher bound of tree depth...\"", 
      "            lowerDepthBound, higherDepthBound = higherDepthBound, lowerDepthBound", 
      "        ", 
      "        if not isinstance(lowerDepthBound, (int, long)) or not isinstance(higherDepthBound, (int, long)):", 
      "            raise TypeError(\"Integer bounds required for decision tree depth.\")", 
      "        ", 
      "        if(tuningSet.shape[0] == 0):", 
      "            raise mlex.DatasetError(\"Please provide examples to tune decision tree on.\")", 
      "        ", 
      "        self.tuningSet = tuningSet", 
      "        self.tunings = []                                                       # This list will hold (depth, tuning_error, tree root) tuples", 
      "        tuningError = np.empty(higherDepthBound - lowerDepthBound + 1)", 
      "        tuningSetLabels = tuningSet['spam'].values", 
      "        for tuningDepth in range(lowerDepthBound, higherDepthBound + 1):            ", 
      "            self.depth = tuningDepth", 
      "            self.train()", 
      "            print \"Trained decision tree on depth: \" + str(self.depth)", 
      "            classifications = self.classify(tuningSet)                          # List of type [-1, 1, 1,....]", 
      "            ", 
      "            # Pay attention to the way that the \"tuningError\" numpy. ndarray ", 
      "            # and the tuningMap dictionary are indexed and filled with values: ", 
      "            # The first is offset by \"lowerDepthBound\" whereas the second is ", 
      "            # offset by zero.", 
      "             ", 
      "            tuningError[tuningDepth - lowerDepthBound] = np.mean((classifications * tuningSetLabels) < 0) # product = -1 means wrong classification", 
      "            ", 
      "            # We need to retain data for every tuning, both for statistical purposes and also for the time", 
      "            # when we will want to test the data trained with a particular depth. So, for every tuning iteration,", 
      "            # we need the following data stored:", 
      "            #", 
      "            #    a) The value of the hyper-parameter (tree depth)", 
      "            #    b) The tuning error (used for statistical purposes)", 
      "            #    c) The root of the trained tree, so that we can classify ", 
      "            #        test data without having to re-train the tree. We should make", 
      "            #        a \"deep copy\" of this tree so that the entire tree is stored.", 
      "            #        This, in essence, turns the current \"DecisionTree\" object into", 
      "            #        a storage space of multiple decision trees, each trained on a different", 
      "            #        value of the \"depth\" hyper-parameter.", 
      "            ", 
      "            tunedDepth, tunedError, trainedTree = self.depth, tuningError[self.depth - lowerDepthBound], copy.deepcopy(self.root)", 
      "            self.tunings.append((tunedDepth, tunedError, trainedTree)) ", 
      "            print \"Classified tuning examples. Tuning error was: \" + str(tuningError[tuningDepth - lowerDepthBound])", 
      "            ", 
      "            # Re-initialize tree for the next iteration by setting root to None. This will cause a memory leak", 
      "            # for the tree that was currently trained; explicitly run the garbage collector to minimize the time ", 
      "            # that this leak is alive.", 
      "            ", 
      "            self.root = None", 
      "            gc.collect()", 
      "            ", 
      "    ", 
      "        # Now that tuning has taken place, set depth to the depth that caused the ", 
      "        # least classification error and make the root of the current object", 
      "        # point to the relevant tree, so that the object is ready to classify", 
      "        # testing points based on the best prediction found in tuning.", 
      "        ", 
      "        self.depth = np.argmin(tuningError) + lowerDepthBound", 
      "        for data in self.tunings:", 
      "            if data[0] == self.depth:", 
      "                self.optimalTuningError = data[1]", 
      "                self.root = data[2]", 
      "                break", 
      "        ", 
      "        # Some printings to add user-friendliness:", 
      "            ", 
      "        print \"Tuned decision tree. Found an optimal depth of \" + str(self.depth) + \" with a tuning error of \" + str(self.optimalTuningError)", 
      "", 
      "</code</pre> "
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "<font color=#ff3300>Extend your implementation to use [information gain](http://en.wikipedia.org/wiki/Information_gain_in_decision_trees) as scoring function. Insert your code for entropy gain here:</font>"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "TODO: add code for information gain here", 
      "", 
      "RESPONSE: The relevant code can be examined in the class code above, but we will still copy it in the cell below for clarity."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "The following is a fraction of the \"scoreFeatures\" method of our classifier:", 
      "", 
      "<pre><code>    ", 
      "    # Use Information Gain for current node", 
      "       ", 
      "    # First, compute cardinalities to weight info gain appropriately", 
      "    cardinalityLarger = trainingData[trainingData[featureName] >= example2[featureName]].shape[0]", 
      "    cardinalitySmaller = trainingData[trainingData[featureName] < example2[featureName]].shape[0]", 
      "    cardinalityCurrent = trainingData.shape[0]", 
      "    fractionLarger = cardinalityLarger / cardinalityCurrent", 
      "    fractionSmaller = cardinalitySmaller / cardinalityCurrent", 
      "", 
      "    # Second, compute all entropies", 
      "                        ", 
      "    currentEntropy = self.__calculateEntropy__(trainingData)", 
      "    entropyLarger =  self.__calculateEntropy__(trainingData[trainingData[featureName] >= example2[featureName]])", 
      "    entropySmaller = self.__calculateEntropy__(trainingData[trainingData[featureName] < example2[featureName]])", 
      "                        ", 
      "    # Third, compute information gain based on both entropies and cardinalities", 
      "                        ", 
      "    totalScore = currentEntropy - (fractionLarger* entropyLarger + fractionSmaller* entropySmaller)", 
      "</code></pre>                                                ", 
      "                    "
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "The calculateEntropy method has been defined as follows:", 
      "", 
      "<pre><code>", 
      "def __calculateEntropy__(self, dataset):", 
      "        ", 
      "        '''", 
      "        Description: Calculate the entropy of a given dataset. ", 
      "        Arguments: ", 
      "            dataset: pandas.DataFrame", 
      "        Return value: the entropy of the dataset (float)", 
      "        '''", 
      "        if dataset.shape[0] == 0:", 
      "            return 0                                                    ", 
      "        if 1 in dataset.groupby('spam').shape.keys():", 
      "                positiveExampleCount = dataset.groupby('spam').shape[1][0]", 
      "        else:", 
      "                positiveExampleCount = 0", 
      "        if -1 in dataset.groupby('spam').shape.keys():", 
      "                negativeExampleCount = dataset.groupby('spam').shape[-1][0]", 
      "        else:", 
      "                negativeExampleCount = 0", 
      "        ", 
      "        positivesFraction = positiveExampleCount / dataset.shape[0]     # division library will take care of quotients", 
      "        negativesFraction = negativeExampleCount / dataset.shape[0]", 
      "        return -positivesFraction * np.log2(positivesFraction) -negativesFraction* np.log2(negativesFraction)", 
      "</code></pre>"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "<font color=#ff3300>Apply your code to the spam dataset. Analyze the result. Things you should discuss: 1. The effect of tree depth on accuracy,", 
      "2. Which features seem to be important for classification.", 
      "    "
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "### Experimental procedure", 
      "", 
      "First, we use the same set-up as the first Practicum session of Friday 09/07. We import the same libraries, set up the same training, tuning and ", 
      "testing dataset portions (including leaving the seed value at 1 to make the output reproducible by the instructors).", 
      "", 
      "Firstly we import all required libraries, as well as a function called \"load\", the definition for which we borrowed from the file KNN.py provided to us", 
      "at the first Practicum session referenced above. This function uses the pickles library to load an object image that has been stored on disk and is very useful", 
      "to us so that we don't have to retrain classifiers in order to show how well they deal with tuning and testing data."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "'''", 
      "Created on Sep 21, 2012", 
      "", 
      "@author: Jason", 
      "'''", 
      "", 
      "import numpy as np", 
      "import pandas as pd", 
      "import pylab as pl", 
      "import DecTree", 
      "from util import load"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Read the dataset from the data file."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "spam_values = np.genfromtxt('../input_data/spambase.data', delimiter=',')", 
      "fl = open('../input_data/spambase.names', 'r')", 
      "lines = [line.strip() for line in fl] # J : strip from beginning and ending whitespace", 
      "fl.close() "
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Append column names to data and change spam labels to 1 and -1, so that it is easier for our classifiers to compute tuning and testing error."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "colnames = [line.partition(':')[0] for line in lines if not (len(line) == 0 or line[0] == '|' or line[0] == '1')]", 
      "colnames.append('spam')", 
      "spam_df = pd.DataFrame(spam_values,columns=colnames)", 
      "spam_df['spam']=2*spam_df['spam']-1"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Establish how many testing and tuning samples we want:"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "nsamples = spam_df.shape[0] ", 
      "ntest = np.floor(.2 * nsamples)", 
      "ntune = np.floor(.1 * nsamples)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Generate test, tune and train datasets. Use a static seed of 1 to make the generation reproducible."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "np.random.seed(1)", 
      "all_indices = np.arange(nsamples) ", 
      "np.random.shuffle(all_indices) ", 
      "test_indices = all_indices[:ntest] ", 
      "tune_indices = all_indices[ntest:(ntest+ntune)] ", 
      "train_indices = all_indices[(ntest+ntune):] ", 
      "spam_train = spam_df.ix[train_indices,:]", 
      "spam_tune = spam_df.ix[tune_indices,:]", 
      "spam_test = spam_df.ix[test_indices,:]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Save the datasets on disk."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "pd.save(spam_train, '../proc_data/training_data/spam_train.pdat')", 
      "pd.save(spam_tune, '../proc_data/training_data/spam_tune.pdat')", 
      "pd.save(spam_test, '../proc_data/testing_data/spam_test.pdat')"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Now we will load some classifiers that we have already trained, in order to show their performance in the tune and test datasets.", 
      "***Please Note:*** "
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# A decision tree classifier trained with Majority Vote, depths 1 to 15", 
      "majVoteTree = load(\"../proc_data/dtreeWithMajVote_1_to_15.pyobj\")", 
      "print \"According to the tuning set, the optimal depth for this tree is: \" + str(majVoteTree.depth)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "According to the tuning set, the optimal depth for this tree is: 5"
       ]
      }
     ], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "We now classify the spam data according to the loaded classifier:"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "classifications = majVoteTree.classify(spam_test)", 
      "testErrorRate = np.mean ( (spam_test['spam'].values * classifications) < 0)", 
      "print 'For this depth, the error on the test set was %0.3f' % testErrorRate"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "For this depth, the error on the test set was 0.083"
       ]
      }
     ], 
     "prompt_number": 8
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Finally, we want to make a general estimate of how well this classifier performs for various depths. We have defined a method that takes all depth values", 
      "considered in the tuning set, prints the relevant tuning error and classifies the test set to report testing error."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "majVoteTree.classifyWithAllDepths(spam_test)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "Classifying with depth: 1.", 
        "For this depth, the tuning error was: 0.397826086957.", 
        "Testing error of this decision tree is: 0.388043478261"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 2.", 
        "For this depth, the tuning error was: 0.219565217391.", 
        "Testing error of this decision tree is: 0.216304347826"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 3.", 
        "For this depth, the tuning error was: 0.15652173913.", 
        "Testing error of this decision tree is: 0.119565217391"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 4.", 
        "For this depth, the tuning error was: 0.139130434783.", 
        "Testing error of this decision tree is: 0.104347826087"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 5.", 
        "For this depth, the tuning error was: 0.108695652174.", 
        "Testing error of this decision tree is: 0.0826086956522"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 6.", 
        "For this depth, the tuning error was: 0.119565217391.", 
        "Testing error of this decision tree is: 0.0858695652174"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 7.", 
        "For this depth, the tuning error was: 0.115217391304.", 
        "Testing error of this decision tree is: 0.0804347826087"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 8.", 
        "For this depth, the tuning error was: 0.128260869565.", 
        "Testing error of this decision tree is: 0.0913043478261"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 9.", 
        "For this depth, the tuning error was: 0.128260869565.", 
        "Testing error of this decision tree is: 0.0913043478261"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 10.", 
        "For this depth, the tuning error was: 0.121739130435.", 
        "Testing error of this decision tree is: 0.0902173913043"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 11.", 
        "For this depth, the tuning error was: 0.121739130435.", 
        "Testing error of this decision tree is: 0.0923913043478"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 12.", 
        "For this depth, the tuning error was: 0.119565217391.", 
        "Testing error of this decision tree is: 0.0902173913043"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 13.", 
        "For this depth, the tuning error was: 0.119565217391.", 
        "Testing error of this decision tree is: 0.0902173913043"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 14.", 
        "For this depth, the tuning error was: 0.117391304348.", 
        "Testing error of this decision tree is: 0.0902173913043"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 15.", 
        "For this depth, the tuning error was: 0.117391304348.", 
        "Testing error of this decision tree is: 0.0902173913043"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Estimated training error with all different depths."
       ]
      }
     ], 
     "prompt_number": 9
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Let's make this a little more visual by using pylab:"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from util import drawError", 
      "# draw tuning error first:", 
      "drawError([data[0] for data in majVoteTree.tunings], [data[1] for data in majVoteTree.tunings], \"Tuning error and depth for \\n Majority Vote Decision Tree\")"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "display_data", 
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEYCAYAAAC9Xlb/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npABM9kRECvD/AbfRpnhGGkuIAAAAAElFTkSuQmCC\n"
      }
     ], 
     "prompt_number": 10
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "So for depth = 1 to 10, tuning error is minimized for depth = 5. How much is it exactly?"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print \"According to the tuning set, the optimal tuning error for this tree is: \" + str(majVoteTree.optimalTuningError)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "According to the tuning set, the optimal tuning error for this tree is: 0.108695652174"
       ]
      }
     ], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "About 11%. What about testing error?"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "drawError([data[0] for data in majVoteTree.tests], [data[1] for data in majVoteTree.tests], \"Testing error and depth for \\n Majority Vote Decision Tree\")"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "display_data", 
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEYCAYAAAC9Xlb/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGPZERFbg/wMuqGE4wwZ/PwAAAABJRU5ErkJggg==\n"
      }
     ], 
     "prompt_number": 12
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "With optimal testing error:"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "sortedTests= sorted(majVoteTree.tests, key=lambda data: data[1])", 
      "print \"According to the test set, the optimal testing error for this tree is: \" + str(sortedTests[0][1]) + \" and is attained for depth = \" + str(sortedTests[0][0]) + \".\""
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "According to the test set, the optimal testing error for this tree is: 0.0804347826087 and is attained for depth = 7."
       ]
      }
     ], 
     "prompt_number": 13
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "So we achieve a better testing error for a value of the depth different than the one that the tuning set found to be optimal. Let's repeat this process", 
      "for the decision tree trained with Information Gain:"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# A decision tree classifier trained with Information Gain, depths 1 to 15", 
      "IGTree = load(\"../proc_data/dtreeWithIG_1_to_15.pyobj\")", 
      "print \"According to the tuning set, the optimal depth for this tree is: \" + str(IGTree.depth)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "According to the tuning set, the optimal depth for this tree is: 6"
       ]
      }
     ], 
     "prompt_number": 14
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "classifications = IGTree.classify(spam_test)", 
      "testErrorRate = np.mean ( (spam_test['spam'].values * classifications) < 0)", 
      "print 'For this depth, the error on the test set was %0.3f' % testErrorRate"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "For this depth, the error on the test set was 0.122"
       ]
      }
     ], 
     "prompt_number": 15
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "IGTree.classifyWithAllDepths(spam_test)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "Classifying with depth: 1.", 
        "For this depth, the tuning error was: 0.397826086957.", 
        "Testing error of this decision tree is: 0.388043478261"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 2.", 
        "For this depth, the tuning error was: 0.221739130435.", 
        "Testing error of this decision tree is: 0.21847826087"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 3.", 
        "For this depth, the tuning error was: 0.180434782609.", 
        "Testing error of this decision tree is: 0.176086956522"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 4.", 
        "For this depth, the tuning error was: 0.139130434783.", 
        "Testing error of this decision tree is: 0.108695652174"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 5.", 
        "For this depth, the tuning error was: 0.126086956522.", 
        "Testing error of this decision tree is: 0.102173913043"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 6.", 
        "For this depth, the tuning error was: 0.113043478261.", 
        "Testing error of this decision tree is: 0.121739130435"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 7.", 
        "For this depth, the tuning error was: 0.126086956522.", 
        "Testing error of this decision tree is: 0.115217391304"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 8.", 
        "For this depth, the tuning error was: 0.265217391304.", 
        "Testing error of this decision tree is: 0.244565217391"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 9.", 
        "For this depth, the tuning error was: 0.271739130435.", 
        "Testing error of this decision tree is: 0.261956521739"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 10.", 
        "For this depth, the tuning error was: 0.291304347826.", 
        "Testing error of this decision tree is: 0.302173913043"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 11.", 
        "For this depth, the tuning error was: 0.310869565217.", 
        "Testing error of this decision tree is: 0.31847826087"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 12.", 
        "For this depth, the tuning error was: 0.45652173913.", 
        "Testing error of this decision tree is: 0.44347826087"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 13.", 
        "For this depth, the tuning error was: 0.521739130435.", 
        "Testing error of this decision tree is: 0.509782608696"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 14.", 
        "For this depth, the tuning error was: 0.530434782609.", 
        "Testing error of this decision tree is: 0.528260869565"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with depth: 15.", 
        "For this depth, the tuning error was: 0.536956521739.", 
        "Testing error of this decision tree is: 0.538043478261"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Estimated training error with all different depths."
       ]
      }
     ], 
     "prompt_number": 16
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "drawError([data[0] for data in IGTree.tunings], [data[1] for data in IGTree.tunings], \"Tuning error and depth for \\n Information Gain Decision Tree\")"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "display_data", 
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEYCAYAAACjl2ZMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XtczffjB/BXySW0RO6lpEguFVrujjZhLYxhbC7Dfs2+\nZC7bvjOGzfgas4sZuW9fZmNsco1sp4QuvvmycqdmYhQtSdHl/fvj8+3o1OnqnD7nfM7r+Xh46HQ+\n53xep3j16X3en/fHQgghQEREimApdwAiItIfljoRkYKw1ImIFISlTkSkICx1IiIFYakTESkIS51K\ndf36ddjY2ICzXsunVqvh6OhY4e1VKhU2btxokCwTJ07E/PnzK7z9r7/+ir59+8LGxgZnzpwxSCaq\nPix1hahfvz5sbGxgY2MDS0tL1K1bV3N7+/btVXrOVq1aITMzExYWFnpOSxYWFnr5um7ZsgV9+vR5\nqudesmQJJk2ahMzMTHh6ej51JpIXS10hHjx4gMzMTGRmZsLJyQn79u3T3B4zZozc8Z5KXl5eic/l\n5+dX6jkqu725EELg+PHj6NWrV5UeX1BQoOdE9LRY6gq3cOFCjBs3TnM7OTkZlpaWmv+MKpUK//rX\nvzBw4EA0b94cs2bNwt9//13pbQHg5MmT8Pf3h5OTE7766is4Ozvj6NGjOnPl5eVhx44d8PPzg5eX\nFzZu3IjHjx8DkIYyHBwcsHbtWrRt2xaTJk3CokWLMGbMGEydOhXNmzfHt99+i/T0dCxbtgxubm54\n+eWXERERofW6i29f3P79++Ht7Q1bW1sMGDAA3333XYmv0+7du9G+fXt07twZW7du1dyfm5uLb775\nBi4uLvD19cX58+fL/D4kJiZi1KhRaNGiBT744AMA0BrWioqKwquvvorWrVtj0aJFSEtL09xnaWmJ\nLVu2wNPTEx06dMAPP/wAIQTOnz+PqVOn4uTJk7CxsUHDhg01j8nKysLo0aPRtGlTTJkyBSkpKSUy\nPXr0CDY2Nnj06BG8vb3h5uYGAEhJScG8efPg7OyM119/HadPn9Y8ZuLEiZg5cyZGjRqFRo0aQa1W\nl/m6SQaCFMfZ2VkcPXpUCCHEwoULxWuvvaa5LykpSVhYWIj8/HwhhBD9+vUTjo6OIjw8XNy4cUP4\n+PiIDRs2VHrb9PR0UbduXbF161Zx8+ZNMX78eFGzZk1NjuK+/PJL4efnJxISEsSVK1eESqUS69at\nE0II8dtvvwkrKysxadIkcevWLZGdnS0WLFggatasKb766iuRnZ0tsrOzxfjx48WoUaPEn3/+KXbt\n2iUaNmwokpKShBBC5/bFqdVqkZCQIPLy8sShQ4eEjY2NuHz5stZrHz16tLh+/boICwsTtWvX1jzP\nqlWrRNeuXcXZs2dFZGSkaNu2rXB0dNT5WgsKCkSTJk3EihUrRGpqqpg1a5aoVauW2LhxoxBCiDNn\nzggHBwdx5MgRce/ePTF9+nQxduxYzeMtLCxEjx49xNmzZ0VERIRwdnYWhw4dEkIIsWXLFtG7d2+t\n/U2YMEE888wzYvfu3SI1NVW8+OKLYt68eTqzFT7/1atXNbf79u0rpk2bJu7cuSM2btwonnnmGc3r\nnjBhgqhXr574/vvvRW5ursjJySn1eUkeLHUFKlrqCxYsKLPUVSqVmD59uub+pUuXitGjR1d62x9/\n/FH06dNHc9/Vq1eFhYVFqaXeq1cvcfz4cc3tn3/+WbzwwgtCCKnULSwsxPXr1zX3L1iwQLi4uGhu\n5+XliUaNGomLFy9qPvfqq6+KlStX6ty+Il577TWxYsUKrdf+n//8R3N/u3btNGU6ePBgTSkLIcT8\n+fOFg4ODzueNiYnRKvyHDx+K2rVrax4/d+5c8cknn2juT0tLE/b29iIvL08IIZVu0X29//77Ytq0\naUIIITZv3qyz1AMDAzW3t2/fLnx9fUt93UVLPTU1VVhbW4sHDx5o7u/Vq5fYvXu35rn9/PxKfS6S\nH4dfCF5eXpqPmzVrpvNX9fK2jYmJ0brPxcUFtra2Op8jKysLJ06cQEBAAOzs7GBnZ4eJEyfixIkT\nmm2aNm1aYjaJr6+v5uPz58/j0aNHaNu2reZzXbt2xbFjx3Rur0tiYiJef/11tGvXDra2tvjpp59w\n9uzZUl9v8+bNNa83NjZW6z5vb+9S9xMTE6P1BqS1tTXc3d01t8PDw7F06VLN18LV1RUPHz5EfHy8\nzhze3t44efJkqfuzsLCo1Pe0qOjoaLi4uKBevXqaz3Xr1g1RUVGa5y7v60ryYqkrnIODA27fvq25\nXXR8VJ98fX3x3//+V3P72rVryMjI0LltvXr14Ovri7CwMKSnpyM9PR1///030tPTNdtYWVlpPcbC\nwgI1atTQ3HZ3d0ft2rVx8eJFzedOnTqFvn37am4X3V6XOXPmwMHBAREREcjIyMCIESMqPH3z2Wef\n1fpaFi3g4nx9fbWmCmZnZ+PChQua235+fpg3b57ma5Geno6srCz4+Photim+r549e2peo67MFX0d\nxXXv3h3Xrl1DVlaW5nNxcXFaM2zK+7qSvFjqCufn54fo6GjEx8fj4sWLWL16dYltKlMApW3r7++P\n+Ph4bN++Hbdu3cJHH31UopiLGjduHD788EPEx8ejoKAAKSkpOHz4cIX3a2VlhYCAACxYsAApKSn4\n5ZdfcOjQIQwbNqzCr+XmzZuwt7eHra0tQkNDERoaWuHHvvDCC1i7di0SEhIQFRWFnTt3lrptt27d\n8OjRI3z++edITU3F/PnztV7PuHHjEBISgsOHD+Px48fIyMgo8XybNm1CQkICjh07hh9//BEvvvgi\nAOm3k8uXL+PBgweabata6ABgb28PHx8fzJ07F3fu3MGWLVuQmJiIgQMHPvVzU/VgqSuci4sLFi5c\niFGjRmHMmDGYMmVKiTnMRW8Xn+Nc0W0bNGiAQ4cOYePGjejevTu6dOmCBg0alDoE88Ybb2DSpEn4\n8MMP0bBhQwwYMACXLl0qc7/FP7dy5Up4enqiX79++O6777Bz5044OzuXun1xn332GXbs2IFWrVph\n+/btCAoKKvW1Fvd///d/mDBhAgIDAzFnzhy8/fbbpW5vaWmJ8PBwHD9+HJ6enqhdu7bWFEIPDw98\n++232LFjBxwcHNCpUyeEhYWV2N+rr76KoKAgLF68GAMGDNA8dtiwYejQoQOaNGlS6msv67UUv2/b\ntm2oW7cufHx8oFarcfToUVhbW5f63GRcLAR/9JIBJCYmonfv3rh37x5L4ClZWlriypUrcHFxkTsK\nmQAeqZPe7N27Fw8fPsSlS5ewYMECPPfccyx0omrGUie9CQ0NRcuWLeHv74+OHTviq6++kjuSIvAH\nI1UGh1+IiBSER+pERArCUleQ5ORkjBw5EnZ2dvj666/ljlPC1KlTsXjxYrlj6PTCCy/g3//+t9wx\nSqhoLhsbGyQnJxs+EBk9Dr8YucrMfFi8eDGSk5Oxbt06WFrK+/N6y5Yt2Lhxo9YZnoZ069YtvP/+\n+zh+/Dj++usvNG/eHIMGDcJ7772Hli1bGnTfzs7OuHPnDqysrGBnZ4c2bdrgrbfewssvv2zQ/Rpa\n/fr1NeP5WVlZqFOnjubEo3Xr1pn86p9KxSN1BYmKioKvr2+VCt2Ul6b966+/0KlTJ2RkZGDFihW4\nd+8ewsLC0LRpU0RGRhp8/xYWFti3bx/u37+PXbt2oXv37nj77bcxZ84cg+/bkCq6nLOupZFJRjKs\nN0OVUHSxpQULFohXXnlF/OMf/xBNmzYVI0eOFOfOnRNCCNG/f39Ro0YNUadOHc1qg1lZWeKbb74R\nHTt2FAMGDBChoaGa5928ebPo1auXmD9/vmjVqpWYN2+emDhxopg5c6YYOXKkaNSokQgICBBZWVli\n/vz5wtHRUbz00ktaC2gtXbpUtGnTRjRs2FCMHTtWREZGCiGEOHfunKhTp46oUaOGqF+/vrCzsxNC\nSItBFV0t8LfffhPDhw8Xrq6uYtmyZeLevXtar3vr1q3C09NTtGnTRrNQly6TJ08W7dq1K/PrmJ6e\nLgICAkTjxo2Fq6urmD9/vrh9+7bm/n79+mlWnCz82ixatEi0aNFCDBw4UJw4caLU5y66gFqhDRs2\niBo1aohLly4JIYTIzc0VP/74o+jfv7/w9PQUGzZsEI8ePdJsf+rUKfHmm2+Kxo0bizZt2oiwsLAS\nuW7evCnGjh0rmjdvLuzt7TWLqRV+vQr/nVTk+17R16brNf7222+iZcuWYs2aNcLNzU2MHz9eCCHE\ngQMHRGBgoGjbtq1YuXKlyMzM1Dz+ypUr4p133hGtWrUSU6ZMEYmJieXuk6qGR+omZvfu3fD09MT5\n8+dha2uLJUuWAJAuSdanTx+sXr0a9+/fh6urK5YtW4adO3di165d+Oc//4ng4GCt9a9jY2ORl5eH\ns2fP4oMPPoAQAps2bcJrr72G33//HWlpafDx8UHdunVx5swZNGnSBMuWLdM83tXVFVFRUbhx4wa6\ndeuGsWPHAgDat2+PtWvXokePHsjMzMS9e/cAaJ+NmJSUhJdeegljxoyBWq1GfHw8Zs6cqfVaN23a\nhB9++AE7duzAggULcPXqVZ1fk2PHjmHIkCFlft0KCgowefJkXL9+HYcOHUJsbKzWlMviZ0rGxcUB\nABISEtC9e3e8++67ZT5/cUOHDoWFhYVmTZhvvvkGISEhWLVqFXbt2oWtW7dq1nhPTU2FSqWCt7c3\nkpOTERkZCScnpxK5Vq5ciZYtW+Lq1atISUlBcHCwzn2X931/2tcGALdv30ZcXBwiIyMREhKC0NBQ\n/POf/8TcuXOhVqsRHR2NpUuXApB+C+zZsyc8PDyQkJCAPn36aJYdIAOQ+6cKla34kXqnTp009508\neVI0a9ZMc1ulUmmO6oQQwtPTU3PEJ4QQH3zwgQgODhZCSEds1tbWWkeLEyZMEEOGDNHc/uSTT0Tj\nxo01t48fPy6cnJx05iwoKBCOjo7i1KlTmucvviTsxIkTxfz584UQQqxcuVKMGTNGc9/ly5dFo0aN\nNMv8WlhYiF27dmnuHzhwoFizZo3OfdetW1ezNKwQ0lrnDRo0EPXr1xdvvPGGzsccOXJEdOzYUXNb\npVJplrfdvHmzsLOz02S5efOmqFmzptZytEXpOlIXQoiOHTuK5cuXCyGE6NmzZ6lLDX/zzTdi6NCh\nOp+7aK5Zs2aJ1157TSQnJ5fYrui/k/K+75V5bbpeo66lkceOHSu2bdumuX369Gnh4eEhhBDi8OHD\nYsCAAVrP5+XlJWJjY8vcJ1UNj9RNTNElXJs1a4bbt29rXVKs8KguMzMTZ8+eRdeuXTX3FV+a1tPT\nE7Vq1dJ6bNHnb9KkCTp06KB1u+gSrqGhoRg+fDhatGiBhg0b4tatWyWWri3NiRMntLK5uroiLy8P\niYmJms+VtuxtcY6OjpqlYQFg2rRpSE9Px9tvv43c3FwA0pH63Llz0adPHzRo0AAjRozAuXPnSl2g\nqkOHDpr3Jpo3b468vDyt1S7Lk5qaigsXLsDR0RFZWVk4efJkqUsNq9XqCl1Obu7cuXBwcECPHj3Q\ns2dP/PLLLyW2qcj3/WlfG1ByaeTw8HBMnTpV8/r69++P5ORk3L59G+Hh4Th27JjmPjs7O1y5cqVa\n3u8wRyx1hbKxsUHnzp1x6tQpzeeKL02raxXF0kquuKysLLzxxhuYMGECLly4gHv37qFly5aax5e2\nJGyhXr16aWW7fPkyatSoofVDpLjSzqzs3bs39u7dW+Zr2blzJ/bv34/NmzcjLS0Nu3btgpAuElPu\na62K0NBQCCHQpUuXcpca7t+/v9YPpdI0atQIS5cuxc2bN/Hhhx/i1Vdf1VquGKjY910fiv/b8fPz\nw/r160ssH9y0aVP4+flBpVJp3ZeZmYnZs2frNRNJWOoKU7Skhg4diuXLl+PSpUtQq9XYvn17mUvT\nVqbgMjMz8eDBAzRv3hwFBQWasilU2pKwhfsYMmQIwsLCsHv3bqSkpGDBggUIDAwsdeZOWQW8ePFi\n3L17F8OHD8eePXuQm5uLtLQ0nD9/XvOD4ObNm2jQoAHs7e1x6dIlrfcG9KEwW3x8PObPn49FixYh\nODhYc93PspYaHjFiBNRqNTZu3IisrCykpKRorRNfaOfOnbhx4wYKCgpQr1491KtXT+fa5pX9vuvD\nuHHj8OmnnyIqKgr5+flITU3VLGX8/PPP4/fff8d3332H9PR05OTkQK1WV/jCHVQ5LHUjV9ayuMXv\nL3773XffxbBhwzB8+HB88sknWLlyJfr161fmc1V0f82aNcPSpUsxbtw4eHp64vHjx+jdu7dmu/KW\nhHVxccHOnTvx73//G/369UPnzp2xcuXKMl9XaUfqzZo1Q0JCAmxsbDB79mw0atQIvXv3hoODAz7+\n+GMAwKRJk9CyZUu0bdsW48aNw6RJk0p9vsouXQsAgYGBeOaZZzBs2DBERUVhxYoVWq+nrKWGGzdu\njKNHjyI6OhpOTk5QqVS4fv16iX2cOnUK3bt3h52dHRYuXIg1a9bgmWeeKZGvKt/3yir+mMGDB+Oj\njz7C119/jcaNG6NHjx6IjY0FIP3WplarcfHiRXTt2hWtWrXCZ599pjVsSPrDk4+IiBSER+pERArC\nUiciUhCWOhGRgrDUiYgUhKVORKQgJc8+MRBekouIqGoqM0mxWo/UC08gMeY/CxYskD2DUnKaQkbm\nZE5j/1NZHH4hIlIQljoRkYKw1ItRqVRyR6gQU8hpChkB5tQ35pRXtS0TYGFhUaXxISIiYyUEkJYG\nXLwIXLgAPPcc0Lq1fvdR2e6sttkvRESmKjcXuHr1SXkX/bugAHB3l/48+6zcSXmkTkSkcfeu7uJO\nTgYcHKTibtdO++/GjQFDztiubHey1InIrAghlXRCQskCf/xYd3G7ugK1a8uTl6VORFTErVtAXNyT\nP6dOSQXdubN2cbu7A02bGvaouypY6kRktu7dk0q7aInn5AA+Pk/+dOsGtGghd9KKY6kTkVnIzATi\n47VLPDUV6NJFu8SdnY3v6LsyWOpEpDg5OcCZM9oFnpwMdOqkXeBt2wI6Lttq0ljqRKQoH34IrFgh\nFXbRAu/QAahVS+50hsd56kSkGCdPAuvXS0fl/7t+OZWDywQQkVF69AiYMgX48ksWemWw1InIKC1Z\nIs0PHzlS7iSmhWPqRGR0fv8d8PMD/vtfoGVLudPIq7LdySN1IjIq+fnA5MnAJ5+w0KuCpU5ERuXL\nL4F69aTxdKq8cks9MjIS7du3h5ubG1atWlXifrVaDVtbW3h7e8Pb2xuLFy82SFAiUr5r16Sx9PXr\nAUseclZJuVMaZ8yYgZCQEDg5OWHgwIEYM2YM7O3ttbbp168fQkNDDRaSiJRPCOCNN4D33pPeIKWq\nKfNnYUZGBgCgb9++cHJygr+/P2JiYkpsxzdAiehpbd4MZGQAM2fKncS0lVnqcXFxcHd319z28PBA\ndHS01jYWFhY4ceIEvLy8MGvWLFy9etUwSYlIsW7elI7QN24ErHhK5FN56i9fly5d8Oeff6JmzZr4\n9ttvMWPGDOzbt0/ntgsXLtR8rFKpFHuNQCKqnGnTgKAgwNNT7iTyU6vVUKvVVX58mfPUMzIyoFKp\ncPr0aQDA9OnTMWjQIAQEBOjcXgiBZs2a4fr166hdbEV5zlMnIl127QLmzQNOnwbq1JE7jfHR6zx1\nW1tbANIMmOTkZBw5cgS+vr5a29y+fVuzw71796Jz584lCp2ISJd794Dp04ENG1jo+lLu8MsXX3yB\noKAg5ObmIjg4GPb29ggJCQEABAUF4aeffsKaNWtgZWWFzp0747PPPjN4aCJShjlzgBEjgF695E6i\nHFwmgIhkceSIdIJRQgJgYyN3GuPFZQKIyOg9eAD83/8Ba9ey0PWNR+pEVO1mzgTu3gW++07uJMaP\nF8kgIqMWHQ388IM07EL6x+EXIqo2jx5JKzB+8QXQqJHcaZSJpU5E1WbpUqBNG2DUKLmTKBfH1Imo\nWiQkAP37SycZOTjIncZ0cPYLERmdwgtfLF7MQjc0ljoRGdxXXwHW1tLSumRYHH4hIoO6dg149lng\n5EnAzU3uNKaHwy9EZDSEkE4yevddFnp1YakTkcFs3gykpwOzZsmdxHxw+IWIDOLWLWl99MOHAS8v\nudOYrsp2J0udiAxixAjA3R345BO5k5g2LhNARLLbtQtITAS2bZM7ifnhkToR6VV6OtChA7BjB9C7\nt9xpTB+HX4hIVpMmAXXrAl9/LXcSZeDwCxHJ5rffgKNHuQKjnDilkYj0ZsMG4P33eeELOXH4hYj0\nIj8faNpUWrDL0VHuNMrBM0qJSBaxsUCLFix0ubHUiUgvDhwAXnhB7hTEUicivWCpGweOqRPRU7t1\nC/DwAO7cAWrWlDuNsnBMnYiq3cGDwIABLHRjwFInoqd24AAQECB3CgI4/EJETyk3F2jcGLh4UZrS\nSPrF4RciqlbHj0sXwGChGweWOhE9Fc56MS4sdSJ6Kix148JSJ6Iq++MP4PZtoFs3uZNQIZY6EVXZ\ngQPAoEFAjRpyJ6FCLHUiqjJOZTQ+nNJIRFWSkwM0aQIkJwMNG8qdRrk4pZGIqkVEBNC5Mwvd2LDU\niahKOOvFOLHUiahKWOrGiaVORJV26RLw8CHg6Sl3EiqOpU5ElVZ4lG5hIXcSKo6lTkSVxqEX48Up\njURUKQ8eAM2bAykpwDPPyJ1G+TilkYgM6tdfgWefZaEbq3JLPTIyEu3bt4ebmxtWrVpV6nZxcXGw\nsrLC7t279RqQiIwLh16MW7mlPmPGDISEhCA8PByrV69GWlpaiW3y8/Px3nvvYdCgQRxiIVIwIVjq\nxq7MUs/IyAAA9O3bF05OTvD390dMTEyJ7VatWoWXX34ZjRs3NkxKIjIKCQmAlRXg7i53EipNmaUe\nFxcH9yLfPQ8PD0RHR2ttk5KSgj179mDq1KkApEF9IlImTmU0flZP+wRvv/02/vWvf2neoS1r+GXh\nwoWaj1UqFVQqVZX3GxYGtG4NtG1b5acgoko6cAB47z25UyibWq2GWq2u8uPLnNKYkZEBlUqF06dP\nAwCmT5+OQYMGIaDIWpsuLi6aIk9LS0PdunWxfv16DBkyRHtHep7SOGsWYG8PzJ2rt6ckojL8/Tfg\n6ChdFKNuXbnTmA+9Tmm0tbUFIM2ASU5OxpEjR+Dr66u1zbVr15CUlISkpCS8/PLLWLNmTYlCN4Q+\nfYBjxwy+GyL6nyNHpP93LHTjVu7wyxdffIGgoCDk5uYiODgY9vb2CAkJAQAEBQUZPGBpevcGJk4E\n8vN51RWi6sBZL6bBpM8o9fAAtm4FunTR69MSUTEFBUCLFsCJE4CLi9xpzItZnVHKIRii6hEfD9jZ\nsdBNAUudiMrFoRfTYdKl3rcvEBkpneVGRIbDUjcdJl3qrVoB1tbSgv1EZBipqcD589LkBDJ+Jl3q\nAIdgiAwtLAzw8wNq15Y7CVWEyZd64RAMERkGh15Mi0lPaQSkXwtfeAFIStL7UxOZvbw8oGlT4OxZ\noGVLudOYJ7Oa0ghIq8U9eAD8+afcSYiUJyZGWhqAhW46TL7ULSw4rk5kKBx6MT0mX+oAS53IUFjq\npoelTkQ6paQAf/wBdO8udxKqDEWUupcXcP06cPeu3EmIlOPQIcDfX7rSEZkORZS6lRXQowcQFSV3\nEiLl2L+fQy+mSBGlDnAIhkifHj8Gjh4FBg2SOwlVlmJKnSchEelPVJQ0XbhJE7mTUGUpptSffRY4\nd06as05ET4ezXkyXYkq9Th3pDdPoaLmTEJk+lrrpUkypAxyCIdKHpCQgLQ3o2lXuJFQViip1vllK\n9PQOHgQGDwYsFdUO5kNR37aePYG4OOmdeyKqmv37gYAAuVNQVSmq1G1tgbZtgVOn5E5CZJqys6Uh\nzAED5E5CVaWoUgc4BEP0NNRqwNtbusg0mSaWOhFpcNaL6TP5i2QUd/u2dNJEWhpQo4bBd0ekGEIA\nrq7Azz8DnTvLnYYKmd1FMopr2lQ6Cy4hQe4kRKbl0iVpkkGnTnInoaehuFIHOARDVBWFC3hZWMid\nhJ6GIkudJyERVR7H05VBcWPqgHRGXM+ewM2bPOogqojMTKBFC+DWLaB+fbnTUFFmP6YOAM7O0puk\nV6/KnYTINBw9Kl3hiIVu+hRZ6oUXo+YQDFHFcOhFORRZ6oA0rs43S4nKJwRLXUkUW+qcAUNUMb//\nDtSuLS2xQaZPsaXu4QGkp0tvlhJR6QoX8OKkAmVQbKlbWgK9e/Nonag8HHpRFsWWOsAhGKLypKcD\nZ84A/frJnYT0RfGlzhkwRKU7fFiaVGBtLXcS0hdFl3qXLtKJSOnpcichMk4celEeRZd6zZqAry9w\n/LjcSYiMT0GBdOk6lrqyKLrUAQ7BEJXm5EmgcWPpDGxSDsWXOk9CItJ2+TIQFAQEBgIzZ8qdhvSt\n3FKPjIxE+/bt4ebmhlWrVpW4f8+ePfD09ISXlxcCAgIQFxdnkKBV5esLnD0LPHwodxIiecXFAS+/\nLC1217QpcPEiMGWK3KlI38pdpdHb2xtffvklnJycMHDgQERFRcHe3l5zf1ZWFurVqwcAiIiIwPz5\n8xGpY7yjOldpLK5HD+CTTwA/P1l2TyQbIYCwMGDZMuDaNWDWLGDyZC7cZUr0ukpjRkYGAKBv375w\ncnKCv78/YmJitLYpLPTC7evUqVOZvNWCQzBkbvLygO+/ly4i/c47wKRJwJUrwIwZLHSlK7PU4+Li\n4O7urrnt4eGB6OjoEtv9/PPPcHZ2xqRJk7B+/Xr9p3xKPAmJzEVWFrBqlXSt0ZAQYMkSafhx3Dhp\nNhgpn17eKH3ppZeQnJyM1atXY9iwYfp4Sr3q1QuIiQFyc+VOQmQYaWnAokVA69bAb78BP/wARETw\n8nTmyKqsO318fPDOO+9obicmJmLQoEGlbj969GgEBwcjOzsb1jpOUVu4cKHmY5VKBZVKVfnEVWBn\nB7i4APHx0hunREqRnAysXAls3QqMGCH9Rtqundyp6Gmo1Wqo1eoqP77Cb5S2atUKgwYNKvFG6dWr\nV+Hi4gKUuc3zAAATZ0lEQVQLCwscOHAAX3/9NQ4cOFByRzK+UQoA06ZJ83HnzJEtApHenDkDfPop\ncOiQNINlxgzpcnSkPHq/nN0XX3yBoKAgPP/883jrrbdgb2+PkJAQhISEAAB27dqFTp06wdvbGz/9\n9BM+/fTTqqc3IJ6ERKZOCECtBgYPlv54ekozWpYtY6HTE4q88LQuN28CnToBqanSsrxEpiI/H/jl\nF6m8MzKk2SzjxkkXtiDlq2x3ljmmriQtWkhj6+fOAR07yp2GqHw5OcC//w0sXw40bAi8/z4wdCgP\nSqhsZlPqwJMhGJY6GbO//wbWrgW++kqaZ75hg/Rvl7NYqCLM6mc+T0IiY5aSIg2ttGkDJCZKZ4Lu\n3y/9u2WhU0WZVakXnoQk49A+UQnnz0un7nfqJJ1LER8vDbt06iR3MjJFZlXqbdpIbzolJcmdhEha\n+nbYMEClApycpNUTv/hC+pioqsxqTN3C4skQjIuL3GnIHBUUSFcbWrYMuHFDOm/i+++BunXlTkZK\nYValDjwZgpkwQe4kZE4ePwa2b5dmstSsCbz3nrQMrpXZ/Q8kQzO7f1J9+kizCoiqw4MHwPr1wOef\nA23bSqf0DxjANz7JcMxqTB2QpjOmpgJ//SV3ElKyO3eAefOkBbZOngR27wbCwwF/fxY6GZbZHanX\nqCGt2hgVJf36S/Q0cnOBq1eBCxekKwkV/n3+PPDKK1Khu7rKnZLMidksE1DUsmXSnGAOw1BF3b37\npLSLFvgffwAODoC7u7Q6YuHfnTpJZzATPa3KdqdZlvrJk8BbbwGnT8udhIxJXp403bVoaRd+/Pix\ndnEXfuzqyjVYyLBY6hXw+LG0lkZKCmBrK3caklN6OjB1qnR1oKQkoHnzkkfd7u7ShZo5Fk5y4IJe\nFVCrFuDjAxw/Ll0ZhszX7t3AvXvAjz9KR906ru1CZFLMbvZLIa4DQwAQGiqds9CpEwudlMFsS50X\no6bsbOl6noMHy52ESH/MttS7d5feKM3OljsJyeXoUaBLF+n9FSKlMNtSr18f6NABiI2VOwnJJTQU\nGDJE7hRE+mW2pQ5wXN2cFRQA+/YBgYFyJyHSL7MudV6M2nz95z/SdFY3N7mTEOmXWZd6795AdLR0\n0gmZl9BQHqWTMpl1qTdqBLRqBfz3v3Inoeq2dy/H00mZzLrUAQ7BmKM//pDOJu7RQ+4kRPrHUud8\ndbOzb590JnGNGnInIdI/ljovRm12OJWRlMzsS93REbCxkda/JuW7f19apdPfX+4kRIZh9qUOcAjG\nnBw+DPTsKf0gJ1Iiljp4EpI54dALKZ1Zrqde3MWL0sWAr1+XOwkZUl4e0KyZtOaPo6PcaYgqprLd\nySN1SFd5f/RImupGynXypFTmLHRSMpY6pCvacFxd+Tj0QuaApf4/PAlJ+fbu5dIApHws9f/hkbqy\nXbwIZGZK66cTKRlL/X88PYGbN4E7d+ROQoZQeJRuyX/xpHD8J/4/NWpIJ6R8+KG01jYpC4deyFxw\nSmMRGRnS9So7dgTWruVRnVLcvQu0bg3cvs2LS5Pp4ZTGp2BrC4SFARcuAJMnA/n5cicifThwAHju\nORY6mQeWejE2NsDBg9Kc9YkTeQENJeDQC5kTDr+U4uFDYNgw6UIa330H1KwpdyKqisePgSZNpNkv\nTZvKnYao8jj8oid160onq2RkAGPGSOVApiciAmjfnoVO5oOlXoY6dYCff5YKfdQoaSkBMi08i5TM\nTbmlHhkZifbt28PNzQ2rVq0qcf+2bdvg6ekJT09PjB07FpcuXTJIULnUrg389JM05XH4cCAnR+5E\nVFFCsNTJ/JRb6jNmzEBISAjCw8OxevVqpKWlad3v4uKCyMhInDlzBgMHDsTHH39ssLByqVUL+OEH\noF49YOhQIDtb7kRUEb//Lv0w9vCQOwlR9Smz1DMyMgAAffv2hZOTE/z9/RETE6O1TY8ePWBrawsA\nCAgIQEREhIGiyqtmTeD77wF7e+DFF4GsLLkTUXkKj9ItLOROQlR9yiz1uLg4uLu7a257eHggOjq6\n1O3XrVuHQAXPHbOykmbCODpKFy7OzJQ7EZWFQy9kjqz09UTh4eHYunUrTpw4Ueo2Cxcu1HysUqmg\nUqn0tftqU6MGsGkTEBQEDBokzWl/5hm5U1Fxt24Bly9LC7URmRK1Wg21Wl3lx5c5Tz0jIwMqlQqn\nT58GAEyfPh2DBg1CQECA1nZnz57F8OHDcejQIbi6uurekYnNUy9PQQEwbRoQHw8cOgQ0aCB3Iipq\n/Xrg11+B7dvlTkL0dPQ6T71wrDwyMhLJyck4cuQIfH19tba5fv06RowYgW3btpVa6EpkaQmsXg34\n+kqXwrt3T+5EVBTPIiVzVe4ZpREREXjzzTeRm5uL4OBgBAcHIyQkBAAQFBSEKVOm4Oeff0arVq0A\nADVr1kRsbGzJHSnsSL2QEMA77wBHjwJHjkhvpJK8Hj6UrkX6xx+AnZ3caYieTmW7k8sE6IEQwNy5\nwP79QHi4dFo6ySc0FPjiC2n4hcjUVbY79fZGqTmzsACWLJHms/fvLx21N2smdyrzxaEXMmc8Utez\njz8Gtm2Tir1lS7nTmJ+CAqBFC+D4caBNG7nTED09HqnLbP586YhdpZJ+/Xd0lDuReYmLk1bWZKGT\nuWKpG8B770lnoPbrJxW7s7PcicwHh17I3LHUDWTWLKnYC4/YXVzkTmQeQkOlSxESmSuWugFNn/6k\n2I8eBdzc5E6kbMnJwF9/SecOEJkrlrqBvfmmVOz9+0vTHYsspUN6tncvEBAgLeVAZK5Y6tVg8mRp\nMTA/P+kEpQ4d5E6kTKGhwFtvyZ2CSF6c0liNvv8emD1bWivG01PuNMqSkSHNNLp5E6hfX+40RPrD\nKY1GbOxYaShm4EDgwAGgSxe5EylHWBjQuzcLnYilXs1GjpSGYgYPBvbtA3x85E6kDFw7nUjC4ReZ\n7N0rjbXv2QP06CF3GtOWlwc0bQqcOQM4OMidhki/9Lr0LhlOYCDw7bfSNU+jouROY9qOH5dO8GKh\nE7HUZTV4sLROzEsvAU9xoROzt3cvh16ICrHUZTZgALBjBzBqlDSPnSpHCGkIi0sDEElY6kagf39g\n1y5pdsyhQ3KnMS0XLwLZ2YC3t9xJiIwDS91I9OkD/PILMH68NCuGKqZwAS8LC7mTEBkHlroR6dlT\nKvTJk4Gff5Y7jWngVEYibZzSaITi44EXXgBWrZLmtZNuaWnSuum3bwN16sidhsgweEapAnTpIp0h\nOWiQNAd7zBi5ExmnAweA555joRMVxVI3Up6e0uJf/v5Abq401k7aOPRCVBKHX4zc+fPStMePPgIm\nTZI7jfF49Eg6i/TyZaBxY7nTEBkOh18Upn176cpJzz0nHbEHBcmdyDio1dISxix0Im0sdRPQtq1U\nYoXFPm2a3Inkx6EXIt1Y6iaiTRup2P38gMePgZkzzXduthDS/HSeqEVUEuepmxBnZ6nYN2+WSn7m\nTOl2Xp7MwarZmTNArVrS0BQRaWOpm5hWrYCzZ6WzTxs2lK6k1KyZNDtm1y7gwQO5Expe4dCLuf6m\nQlQWzn5RgD//lIpuzx4gOhro21da0jcwUCp8pfHxAT79VFozh0jpKtudLHWF+ftv4OBBqeDDwgB3\nd6nghw2TPjZ1N28CHTtKZ5HWrCl3GiLDY6mTxuPH0pj7nj3Sn3r1pIIfOhTo3h2oUUPuhJW3bh0Q\nESGtQ09kDljqpJMQwH/+86Tgb98GXnxRKvgBAwBra7kTVsyLLwKvvQa88orcSYiqB0udKuTatScF\nf/q0NFVy6FCpNO3t5U5X0p070jTGmTOB69eBBg3kTkRUPVjqVGl37wL790sFHx4urTszbJhU8m3a\nyJfr0iUp0y+/AAkJ0jo4EyZIP3iIzAVLnZ5KdjZw9KhUpnv3SkfthePw3boBlgacBFtQAMTEPPkN\nIiNDmro4dKj0m0Tt2obbN5GxYqmT3hQv2fv3n5Rs//76KdmcHO0fIg0bPvktwdA/RIhMAUudDObi\nxScFn5goDYcMHSpd0MPOruLPo2u4p/C3AVdXw+UnMkUsdaoWt29Ll97bs0eaNvnss0+KuVWrktsn\nJT35gRAf/+SN2YAArrRIVBaWOlW7rCzpgh579khF7+AgFXbPnkBUlPRG519/SWe4Dh0KPP88ULeu\n3KmJTANLnWSVlwecOPFkyYJevUz7ZCciubHUiYgUpLLdybkFREQKUm6pR0ZGon379nBzc8OqVatK\n3H/hwgX06NEDderUwWeffWaQkNVJrVbLHaFCTCGnKWQEmFPfmFNe5Zb6jBkzEBISgvDwcKxevRpp\naWla9zdq1AirVq3CnDlzDBayOpnKN9oUcppCRoA59Y055VVmqWdkZAAA+vbtCycnJ/j7+yMmJkZr\nm8aNG6Nbt26oyXVQiYhkV2apx8XFwb3IItweHh6Ijo42eCgiIqqaMme/hIeHY+PGjdi+fTsAYO3a\ntUhJScHHH39cYttFixahfv36mD17tu4d8dpjRERVUpnZL1Zl3enj44N33nlHczsxMRGDBg0yeCgi\nIqqaModfbG1tAUgzYJKTk3HkyBH4+vrq3JalTUQkv3JPPoqIiMCbb76J3NxcBAcHIzg4GCEhIQCA\noKAg/PXXX/Dx8cH9+/dhaWkJGxsbnDt3DvXr16+WF0BEREUIA4uIiBDu7u7C1dVVfPXVV4beXZVc\nv35dqFQq4eHhIfr16ye2bdsmd6RS5eXlCS8vL/Hiiy/KHaVUDx48EOPHjxdubm6iffv24uTJk3JH\n0mndunWiR48eokuXLmLGjBlyx9F4/fXXRZMmTUTHjh01n7t//74YMmSIcHR0FEOHDhWZmZkyJpTo\nyjlnzhzh7u4uvL29xYwZM8TDhw9lTCjRlbPQihUrhIWFhbh7964MybSVlnPTpk3C3d1deHh4iHff\nfbfc5zF4qXt5eYmIiAiRnJws2rVrJ1JTUw29y0q7deuWOH36tBBCiNTUVNG6dWtx//59mVPp9tln\nn4mxY8eKwMBAuaOUavbs2WLevHkiOztb5Obmir///lvuSCXcvXtXODs7iwcPHoj8/HwxePBgcejQ\nIbljCSGEiIyMFPHx8Vr/uZctWyamTZsmcnJyxD/+8Q+xfPlyGRNKdOU8fPiwyM/PF/n5+WLKlCli\nw4YNMiaU6MophHQwN3DgQOHs7GwUpa4r5++//y66d+8uLl26JIQQ4s6dO+U+j0GXCajIPHdj0KxZ\nM3h5eQEA7O3t0aFDB5w6dUrmVCXduHEDBw4cwJQpU4z6PYzw8HDMnTsXderUgZWVlea9GWNibW0N\nIQQyMjKQnZ2Nhw8fwq4yi8IbUJ8+fUpkiY2NxeTJk1G7dm1MmjTJKP4f6co5YMAAWFpawtLSEgMH\nDkRERIRM6Z7QlRMAZs2ahU8//VSGRLrpynnw4EFMnjwZbm5uAKTzgspj0FI3xXnuV65cQWJiIp59\n9lm5o5Qwc+ZMLF++HJZGfDmgGzduICcnB1OnToWvry+WLVuGnJwcuWOVYG1tjTVr1sDZ2RnNmjVD\nr169jPJ7Xqjo/yV3d3fExsbKnKh869evR2BgoNwxdNqzZw8cHBzQuXNnuaOU6fDhw0hISEC3bt0w\nZcoUnDt3rtzHGG87yCAzMxOjR4/G559/jnr16skdR8u+ffvQpEkTeHt7G/VRek5ODi5duoQRI0ZA\nrVYjMTERO3bskDtWCampqZg6dSrOnTuH5ORknDx5Evv375c7VqmM+Xuuy0cffQQbGxuMHDlS7igl\nPHz4EEuWLMGiRYs0nzPWr29OTg7u3buHY8eOYejQoZg2bVq5jzFoqfv4+ODChQua24mJiejevbsh\nd1llubm5GDFiBMaNG4ehQ4fKHaeEEydOIDQ0FK1bt8aYMWPw66+/Yvz48XLHKsHV1RXt2rVDYGAg\nrK2tMWbMGBw8eFDuWCXExsaie/fucHV1RaNGjTBy5EhERkbKHatUPj4+OH/+PADg/Pnz8PHxkTlR\n6bZs2YKwsDBs3bpV7ig6Xb16FcnJyfD09ETr1q1x48YNdO3aFXfu3JE7Wgndu3fH6NGjYW1tjcDA\nQFy4cKHc33wNWuqVmecuJyEEJk+ejI4dO+Ltt9+WO45OS5YswZ9//omkpCT88MMP8PPzw3fffSd3\nLJ3c3NwQExODgoIC7N+/H88//7zckUro06cPTp06hXv37uHRo0c4ePAg/P395Y5VKl9fX2zatAnZ\n2dnYtGmT0R4cHTp0CMuXL0doaCjq1KkjdxydOnXqhNu3byMpKQlJSUlwcHBAfHw8mjRpIne0Enr0\n6IGDBw9CCIGYmBi0adOm/K+r/t/D1aZWq4W7u7to06aN+PLLLw29uyo5duyYsLCwEJ6ensLLy0t4\neXmJgwcPyh2rVGq12qhnv1y8eFH4+voKT09PMXv2bPHgwQO5I+m0efNm0bdvX9GtWzcxb948kZ+f\nL3ckIYQQr7zyimjevLmoVauWcHBwEJs2bTLKKY2FOWvWrCkcHBzExo0bhaurq2jVqpXm/9HUqVPl\njqnz61lU69atjWL2i66ceXl5IigoSLi7u4thw4aJ2NjYcp+n2q58REREhsc3SomIFISlTkSkICx1\nIiIFYakTESkIS52ISEFY6kRECvL/duOh6H0CDIEAAAAASUVORK5CYII=\n"
      }
     ], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "drawError([data[0] for data in IGTree.tests], [data[1] for data in IGTree.tests], \"Testing error and depth for \\n Information Gain Decision Tree\")"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "display_data", 
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEYCAYAAACjl2ZMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkzoRkQlhUiciMiH/B2ASRiO4ySAwAAAAAElFTkSuQmCC\n"
      }
     ], 
     "prompt_number": 18
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "sortedTests= sorted(IGTree.tests, key=lambda data: data[1])", 
      "print \"According to the tuning set, the optimal tuning error for this tree is: \" + str(sortedTests[0][1])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "According to the tuning set, the optimal tuning error for this tree is: 0.102173913043"
       ]
      }
     ], 
     "prompt_number": 18
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "So Information Gain does slightly worse than Majority Vote and the testing error appears to be reaching a minimum at depth = 5. After that depth, the decision tree", 
      "appears to be **overfitting** the data!"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "### Discussion ", 
      "", 
      "Compared to Hector's results using a variety of $\\mathcal{K}$ for the $\\mathcal{K}$-nearest neighbors algorithm, our decision tree implementations appear to", 
      "be faring better (at least for the range of hyper-parameter values which we had time to examine). Notably, our best testing error computation (8.3%), attained", 
      "with the Majority Vote metric, is about 10.7% better than Hector's optimal testing error of 19%.", 
      "", 
      "This can be due to a variety of reasons. The most notable feature is that we have made sure that the features that the decision tree should sequentially examine", 
      "are the ones that are the highest scored at each point, either through majority voting or information gain. This makes sure that the splittings of the tree", 
      "are as \"pure\" as possible, according to the metric used. The K-nn algorithm can't do that by nature: all features are **equally valued** for it!", 
      "", 
      "In what follows, we show how the features are sorted with respect to their Information Gain. As mentioned in the comments, please allow the sortFeatures()", 
      "method some time to execute fully, since it is rather expensive from a computational perspective when applied to the full dataset."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "atestTree = DecTree.DecisionTree(spam_train, 5, True)", 
      "# The following method sorts the features in descending order according to their score through Information Gain.", 
      "# Give it some time to finish (approx. 3 min in an i3 quadcore with 2.6Ghz/Core + 6GB of RAM)", 
      "# because it scans all feature vectors in their entirety.", 
      "print atestTree.__sortFeatures__(spam_train, spam_train.columns)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "[('char_freq_$', 0.053999999999999999, 0.25547313451781217), ('char_freq_!', 0.079000000000000001, 0.24642707891131355), ('word_freq_remove', 0.029999999999999999, 0.20814359707061136), ('word_freq_free', 0.089999999999999997, 0.19957328880005598), ('word_freq_your', 0.41999999999999998, 0.18659543829576763), ('word_freq_money', 0.02, 0.17820450284669243), ('capital_run_length_longest', 19.0, 0.1459270941437435), ('capital_run_length_average', 3.1549999999999998, 0.14579062919725561), ('word_freq_hp', 0.10000000000000001, 0.14474574616863567), ('word_freq_000', 0.13, 0.14264575496422693), ('word_freq_our', 0.050000000000000003, 0.12633446871019616), ('capital_run_length_total', 69.0, 0.12450231699642578), ('word_freq_hpl', 0.089999999999999997, 0.11429470633019545), ('word_freq_george', 0.20000000000000001, 0.11391030120901857), ('word_freq_you', 0.72999999999999998, 0.1046392877336505), ('word_freq_all', 0.23999999999999999, 0.1010909584849683), ('word_freq_business', 0.059999999999999998, 0.094279735048632407), ('word_freq_internet', 0.029999999999999999, 0.089435905255028203), ('word_freq_credit', 0.029999999999999999, 0.086727737907620783), ('word_freq_receive', 0.029999999999999999, 0.085791434314323678), ('word_freq_over', 0.089999999999999997, 0.073854946762701768), ('word_freq_address', 0.080000000000000002, 0.071826146009200342), ('word_freq_mail', 0.050000000000000003, 0.069583779074771868), ('word_freq_order', 0.050000000000000003, 0.066623158647081238), ('word_freq_email', 0.059999999999999998, 0.064291703240298315), ('word_freq_1999', 0.070000000000000007, 0.062118880974974755), ('char_freq_#', 0.0060000000000000001, 0.056326584875325825), ('word_freq_addresses', 0.02, 0.05535170147844648), ('word_freq_labs', 0.11, 0.052362704310248809), ('word_freq_lab', 0.12, 0.048581233914593347), ('word_freq_85', 0.23000000000000001, 0.048083619179049353), ('word_freq_make', 0.070000000000000007, 0.044814297352277266), ('word_freq_edu', 0.10000000000000001, 0.041266688809824204), ('word_freq_650', 0.089999999999999997, 0.039761415456231242), ('word_freq_people', 0.11, 0.038951286242148497), ('word_freq_meeting', 0.44, 0.036992600991692326), ('word_freq_will', 0.28000000000000003, 0.035906614143150439), ('word_freq_re', 0.56000000000000005, 0.028982849939652611), ('word_freq_telnet', 0.39000000000000001, 0.026692848113289092), ('word_freq_415', 0.17000000000000001, 0.023613447907151031), ('word_freq_pm', 0.20000000000000001, 0.022127036784592824), ('word_freq_original', 0.23000000000000001, 0.022080291290979548), ('word_freq_data', 0.17000000000000001, 0.02133346586022955), ('char_freq_(', 0.28000000000000003, 0.021317401948767079), ('word_freq_857', 0.46000000000000002, 0.01996140459994078), ('word_freq_project', 0.27000000000000002, 0.019559249924431921), ('word_freq_technology', 0.089999999999999997, 0.018743290517881372), ('word_freq_report', 0.040000000000000001, 0.017988418118174865), ('word_freq_conference', 0.10000000000000001, 0.016113397076231717), ('word_freq_font', 0.070000000000000007, 0.015268561436711847), ('char_freq_[', 0.029999999999999999, 0.011770427649779092), ('char_freq_;', 0.078, 0.010027660087751133), ('word_freq_direct', 0.53000000000000003, 0.0037750271325995843), ('word_freq_3d', 0.17000000000000001, 0.0037385725239406087), ('word_freq_parts', 0.40000000000000002, 0.0031355762150127031), ('word_freq_table', 0.11, 0.0026272920475158834), ('word_freq_cs', None, 0)]"
       ]
      }
     ], 
     "prompt_number": 19
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "So it is made clear that the feature \"char_freq_$ \\scriptsize{\\$} $\", representing the frequency of the dollar sign in an e-mail, has the highest correlation with the \"spam\" label.", 
      "This feature is closely followed by the frequency of the exclamation point character, then followed by the frequency of \"remove\", \"free\", etc. This makes", 
      "perfect sense in the real world: spam e-mail typically makes huge monetary ($$$) promises, makes exaggerated claims in an enthusiastic manner!!!!, and contains", 
      "words such as \"free\" (free products), and \"remove\" (remove pests from your home with the new revolutionary Pets-Are-A-Go 9000 etc). ", 
      "", 
      "So, in the spam dataset, not all features are equal. What this means is that the assumption that KNN does, i.e that all features are equal, ", 
      "is not particularly valid fot this dataset."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Part II: Extending k-nn", 
      "", 
      "<font color=#ff3300>Implement the weighted distance idea discussed in CIML for k-nearest neighbors. Feel free to extend the ", 
      "    code linked to above. Please provide your modified code here:</font>"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "TODO: insert weighted distance k-nn code here", 
      "", 
      "RESPONSE: I was unfortunately unable to implement an idea for Weighted Features K-NN, due to a lack of time as well as a recent laptop breakdown,", 
      "which made me lose an entire afternoon of work."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "<font color=#ff3300>Compare your new weighted k-nn algorithm to the original algorithm provided using the spam dataset</font>. "
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "#TODO: insert analysis here"
     ], 
     "language": "python", 
     "outputs": []
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Part III: Compare k-nn and decision tree performance on the spam dataset", 
      "", 
      "<font color=#ff3300>Discuss performance and any other suitable characteristics of k-nn and decision tree using the spam dataset as example.</font>"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Here is the performance of Hector's KNN classifier on the test data (testing error per value of K):"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "HectorsKNN = load(\"../proc_data/HectorsKNN_1_to_41.pyobj\") # Hector's data trained for 1 to 41", 
      "HectorsKNN.classifyWithAllK(spam_test)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "Classifying with 1 - nearest neighbors.", 
        "Testing error was: 0.13152173913."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 3 - nearest neighbors.", 
        "Testing error was: 0.142391304348."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 5 - nearest neighbors.", 
        "Testing error was: 0.158695652174."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 7 - nearest neighbors.", 
        "Testing error was: 0.169565217391."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 9 - nearest neighbors.", 
        "Testing error was: 0.166304347826."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 11 - nearest neighbors.", 
        "Testing error was: 0.169565217391."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 13 - nearest neighbors.", 
        "Testing error was: 0.183695652174."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 15 - nearest neighbors.", 
        "Testing error was: 0.186956521739."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 17 - nearest neighbors.", 
        "Testing error was: 0.204347826087."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 19 - nearest neighbors.", 
        "Testing error was: 0.21847826087."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 21 - nearest neighbors.", 
        "Testing error was: 0.222826086957."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 23 - nearest neighbors.", 
        "Testing error was: 0.226086956522."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 25 - nearest neighbors.", 
        "Testing error was: 0.228260869565."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 27 - nearest neighbors.", 
        "Testing error was: 0.238043478261."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 29 - nearest neighbors.", 
        "Testing error was: 0.238043478261."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 31 - nearest neighbors.", 
        "Testing error was: 0.253260869565."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 33 - nearest neighbors.", 
        "Testing error was: 0.246739130435."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 35 - nearest neighbors.", 
        "Testing error was: 0.247826086957."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 37 - nearest neighbors.", 
        "Testing error was: 0.25."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 39 - nearest neighbors.", 
        "Testing error was: 0.252173913043."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "Classifying with 41 - nearest neighbors.", 
        "Testing error was: 0.24347826087."
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": []
      }
     ], 
     "prompt_number": 24
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Through pylab:"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "drawError([data[0] for data in HectorsKNN.testingData], [data[1] for data in HectorsKNN.testingData], \"Training error and depth for \\n Hector's KNN classifier\")"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "display_data", 
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEYCAYAAABfgk2GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n"
      }
     ], 
     "prompt_number": 27
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "So it's easy to see that, after a minimum testing error for k = 1, Hector's classifier doesn't perform as well as our own."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Part IV: Feature weights in k-nn", 
      "", 
      "As discussed in class k-nn uses all features equally. In this dataset we know not all features are equally informative. The last part of your homework ", 
      "is to propose a method for weighting features in k-nn. ", 
      "", 
      "<font color=#ff3300>Design and implement a method to weight features in the k-nn classifier</font>", 
      "", 
      "Hint: you can base weights on scoring functions you have used in decision tree building"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "TODO: Discuss the method you have designed and insert source code here:", 
      "", 
      "RESPONSE: For the reasons outlined in part II, I was unable to complete part IV."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "<font color=#ff3300>Compare the performance of your new k-nn classifier to the other classifiers you have defined so far on the spam dataset</font>"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "No time to implement WFKNN :("
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Handing-in", 
      "", 
      "Use the [class handin system](http://inclass.umiacs.umd.edu/perl/handin.pl?course=cmsc726) to handin your work. You have to", 
      "turn in this IPython notebook (after editing of course) `PA01.ipynb`. There are two other (optional) files you can turn in", 
      "`pa01.tar.gz` and `pa01.zip` which you can use to turn in any source code you used."
     ]
    }
   ]
  }
 ]
}