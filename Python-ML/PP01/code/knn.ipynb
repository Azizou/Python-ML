{
 "metadata": {
  "name": "knn"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": [
      "##Practicum 1: K-nearest neighbors", 
      "", 
      "Welcome to the first practicum session. Our goal today is to introduce some good practices for your ML projects. We'll", 
      "use $K$-nearest neighbors algorithm and an email spam dataset for practice. Our goals today are to:", 
      "", 
      "* Learn how to setup a project ", 
      "* Getting data from the UCI ML dataset repository ", 
      "* Review the *train/tune/test* partitioning of data ", 
      "* Implement $K$-nearest neighbors ", 
      "* Estimate generalization error of the new classifier ", 
      "", 
      "###Project layout", 
      "Most of our projects have a few components that we need to keep track of:", 
      "", 
      "1. Method code ", 
      "2. Problem (input) data ", 
      "3. Processed (intermediate) data ", 
      "4. Result (output) data ", 
      "5. Analysis doc: text, figures and code ", 
      "", 
      "It's a good idea to layout your project directory this way as well:", 
      "", 
      "<pre>", 
      " project_dir", 
      " |- pa01 (this is where source goes, but use a meaningful name so you can import nicely in python", 
      " |- input_data (just put data as you get it right here)", 
      " |- proc_data (this is where you put the data after you preprocess it for use)", 
      " |--|- train_data", 
      " |--|- test_data (it's a good idea to use physical separation if you can)", 
      " |- output_data (put data you need to write your analysis here, e.g., predicted labels)", 
      " |- doc (this is where you can put auxiliary files for your analysis)", 
      " |- analysis.ipynb (your notebook file used for documentation/analysis)", 
      "</pre>", 
      "", 
      "It's a good idea to have a shell script that does this automatically.", 
      "", 
      "###The spam dataset", 
      "", 
      "We'll use a dataset of email messages. The task in this case will be to identify spam messages. We'll download the data", 
      "from the UCI ML data repository: http://archive.ics.uci.edu/ml/datasets/Spambase. Download the data files and store in the", 
      "`input_data` directory. ", 
      "", 
      "Let's preprocess the data a bit to make it easier to use later on. And also do our train/tune/test partitioning now."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import numpy as np", 
      "", 
      "# read spam dataset from file", 
      "spam_values = np.genfromtxt('../input_data/spambase.data', delimiter=',')"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# let's take a look at some values", 
      "spam_values[:6,:4]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 5, 
       "text": [
        "array([[ 0.  ,  0.64,  0.64,  0.  ],", 
        "       [ 0.21,  0.28,  0.5 ,  0.  ],", 
        "       [ 0.06,  0.  ,  0.71,  0.  ],", 
        "       [ 0.  ,  0.  ,  0.  ,  0.  ],", 
        "       [ 0.  ,  0.  ,  0.  ,  0.  ],", 
        "       [ 0.  ,  0.  ,  0.  ,  0.  ]])"
       ]
      }
     ], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "# and let's take a look at some labels", 
      "spam_values[:,-1]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 63
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "# now let's read the column names", 
      "fl = open('../input_data/spambase.names', 'r')", 
      "lines = [line.strip() for line in fl] # J : strip from beginning and ending whitespace", 
      "fl.close()", 
      "", 
      "# J: For every line which is not empty and does not start with a | or a 1 (i.e contains a feature name)", 
      "# copy the feature name into colnames vector.", 
      "colnames = [line.partition(':')[0] for line in lines if not (len(line) == 0 or line[0] == '|' or line[0] == '1')]", 
      "", 
      "# append the label name (\"spam\") to the \"colnames\" vector", 
      "colnames.append('spam')"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "It's good practice to keep column names close to the data, so we are going to use the `DataFrame` class provided by", 
      "the `pandas` library (installed by the Enthought distribution)."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "import pandas as pd", 
      "spam_df = pd.DataFrame(spam_values,columns=colnames) # J: spam_df is a DataFrame object now"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "# finally make the spam labels +1 and -1 since we are going to use this in the knn classifier", 
      "spam_df['spam']=2*spam_df['spam']-1 #J: 2*1 - 1 = 1, 2* 0 -1 = -1"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 8
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "spam_df.ix[:3,-3:]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">", 
        "<table border=\"1\">", 
        "  <thead>", 
        "    <tr>", 
        "      <th></th>", 
        "      <th>capital_run_length_longest</th>", 
        "      <th>capital_run_length_total</th>", 
        "      <th>spam</th>", 
        "    </tr>", 
        "    </thead>", 
        "    <tbody>", 
        "    <tr>", 
        "      <td><strong>0</strong></td>", 
        "      <td>  61</td>", 
        "      <td>  278</td>", 
        "      <td> 1</td>", 
        "    </tr>", 
        "    <tr>", 
        "      <td><strong>1</strong></td>", 
        "      <td> 101</td>", 
        "      <td> 1028</td>", 
        "      <td> 1</td>", 
        "    </tr>", 
        "    <tr>", 
        "      <td><strong>2</strong></td>", 
        "      <td> 485</td>", 
        "      <td> 2259</td>", 
        "      <td> 1</td>", 
        "    </tr>", 
        "    <tr>", 
        "      <td><strong>3</strong></td>", 
        "      <td>  40</td>", 
        "      <td>  191</td>", 
        "      <td> 1</td>", 
        "    </tr>", 
        "  </tbody>", 
        "</table>", 
        "</div>"
       ], 
       "output_type": "pyout", 
       "prompt_number": 9, 
       "text": [
        "   capital_run_length_longest  capital_run_length_total  spam", 
        "0                          61                       278     1", 
        "1                         101                      1028     1", 
        "2                         485                      2259     1", 
        "3                          40                       191     1"
       ]
      }
     ], 
     "prompt_number": 9
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Now let's partition into train, tune and test using the 70/10/20 rule"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "# J: Apparently DataFrame.shape is a list or something and the first cell contains the number of samples in the DataFrame", 
      "nsamples = spam_df.shape[0] ", 
      "ntest = floor(.2 * nsamples)", 
      "ntune = floor(.1 * nsamples)", 
      "", 
      "# we want to make this reproducible so we seed the random number generator", 
      "np.random.seed(1)", 
      "all_indices = np.arange(nsamples)+1 #J :+1 to shift the array right and avoid the zero index", 
      "# J: important to shuffle so that you don't know which portion is training, which is testing and which is tuning data", 
      "np.random.shuffle(all_indices) ", 
      "test_indices = all_indices[:ntest] # J: Get shuffled test indices first", 
      "tune_indices = all_indices[ntest:(ntest+ntune)] # J: tune indices second", 
      "train_indices = all_indices[(ntest+ntune):] # J: train indices (the majority) last", 
      "", 
      "# J : now that the \"*indices\" arrays have been shuffled, you can actually draw the relevant data through", 
      "# DataFrame.ix. The second argument includes all columns, labels included.", 
      "spam_train = spam_df.ix[train_indices,:] ", 
      "spam_tune = spam_df.ix[tune_indices,:]", 
      "spam_test = spam_df.ix[test_indices,:]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 10
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "And now save the data in the `proc_data` directories. We won't touch the original data any further."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "pd.save(spam_train, '../proc_data/training_data/spam_train.pdat')", 
      "pd.save(spam_tune, '../proc_data/training_data/spam_tune.pdat')", 
      "pd.save(spam_test, '../proc_data/testing_data/spam_test.pdat')"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# J: This will be my cell for tests on the data", 
      "#from __future__ import division", 
      "tupleList = [('a', 'b', 'd')]", 
      "range(1, 12, 2)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 12, 
       "text": [
        "[1, 3, 5, 7, 9, 11]"
       ]
      }
     ], 
     "prompt_number": 12
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Data exploration", 
      "", 
      "Let's take a look at the data a bit.", 
      "", 
      "#####J: this is where I will need to have a look at \"homogeneous\" features to sort on to make my dtree more effective."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# how many samples and features do we have", 
      "print len(spam_train.columns)", 
      "print spam_train.shape # J: Dataframe.shape should be clear now."
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "58", 
        "(3221, 58)"
       ]
      }
     ], 
     "prompt_number": 13
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# how many samples do we have of each class", 
      "spam_train.groupby('spam').shape "
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 14, 
       "text": [
        "spam", 
        "-1      (1948, 58)", 
        " 1      (1272, 58)"
       ]
      }
     ], 
     "prompt_number": 14
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# what is the mean frequency per label for a few features", 
      "grouped_dat= spam_train.groupby('spam').mean()", 
      "grouped_dat"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 17, 
       "text": [
        "<class 'pandas.core.frame.DataFrame'>", 
        "Index: 2 entries, -1.0 to 1.0", 
        "Data columns:", 
        "word_freq_make                2  non-null values", 
        "word_freq_address             2  non-null values", 
        "word_freq_all                 2  non-null values", 
        "word_freq_3d                  2  non-null values", 
        "word_freq_our                 2  non-null values", 
        "word_freq_over                2  non-null values", 
        "word_freq_remove              2  non-null values", 
        "word_freq_internet            2  non-null values", 
        "word_freq_order               2  non-null values", 
        "word_freq_mail                2  non-null values", 
        "word_freq_receive             2  non-null values", 
        "word_freq_will                2  non-null values", 
        "word_freq_people              2  non-null values", 
        "word_freq_report              2  non-null values", 
        "word_freq_addresses           2  non-null values", 
        "word_freq_free                2  non-null values", 
        "word_freq_business            2  non-null values", 
        "word_freq_email               2  non-null values", 
        "word_freq_you                 2  non-null values", 
        "word_freq_credit              2  non-null values", 
        "word_freq_your                2  non-null values", 
        "word_freq_font                2  non-null values", 
        "word_freq_000                 2  non-null values", 
        "word_freq_money               2  non-null values", 
        "word_freq_hp                  2  non-null values", 
        "word_freq_hpl                 2  non-null values", 
        "word_freq_george              2  non-null values", 
        "word_freq_650                 2  non-null values", 
        "word_freq_lab                 2  non-null values", 
        "word_freq_labs                2  non-null values", 
        "word_freq_telnet              2  non-null values", 
        "word_freq_857                 2  non-null values", 
        "word_freq_data                2  non-null values", 
        "word_freq_415                 2  non-null values", 
        "word_freq_85                  2  non-null values", 
        "word_freq_technology          2  non-null values", 
        "word_freq_1999                2  non-null values", 
        "word_freq_parts               2  non-null values", 
        "word_freq_pm                  2  non-null values", 
        "word_freq_direct              2  non-null values", 
        "word_freq_cs                  2  non-null values", 
        "word_freq_meeting             2  non-null values", 
        "word_freq_original            2  non-null values", 
        "word_freq_project             2  non-null values", 
        "word_freq_re                  2  non-null values", 
        "word_freq_edu                 2  non-null values", 
        "word_freq_table               2  non-null values", 
        "word_freq_conference          2  non-null values", 
        "char_freq_;                   2  non-null values", 
        "char_freq_(                   2  non-null values", 
        "char_freq_[                   2  non-null values", 
        "char_freq_!                   2  non-null values", 
        "char_freq_$                   2  non-null values", 
        "char_freq_#                   2  non-null values", 
        "capital_run_length_average    2  non-null values", 
        "capital_run_length_longest    2  non-null values", 
        "capital_run_length_total      2  non-null values", 
        "dtypes: float64(57)"
       ]
      }
     ], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "We can plot these frequencies."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import pylab as plt", 
      "plt.figure()", 
      "grouped_dat.ix[:,-15:-3].T.plot(kind='bar')", 
      "plt.show()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "display_data", 
       "png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAFFCAYAAAAjC2xEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQ7GV+rN3RwAAAAASUVORK5CYII=\n"
      }
     ], 
     "prompt_number": 16
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###$K$-nearest neighbors", 
      "", 
      "Now let's implement the $K$-nearest neighbor classifier. It's good practice to separate this kind of code from your analysis", 
      "notebook. So we'll implement it in file `knn.py` under the sourcecode folder we defined above. It is much more efficient to use", 
      "matrix computations whenever possible, and we'll do so here. To compute distance between a training sample $x$ and a testing ", 
      "sample $y$, we'll first compute their squared Euclidean distance:", 
      "", 
      "$$", 
      "\\| x - y \\|_2^2 = (x-y)^T(x-y) = x^Tx + y^Ty - 2 x^Ty.", 
      "$$", 
      "", 
      "So, given matrices of training samples $X$ and testing samples $Y$, we'll compute the product $XY^T$, compute the norm", 
      "$x^Tx$ for training samples and then iterate over testing samples to finally compute the squared distances. Notice that", 
      "we are using space O(ntraining_samples * ntesting_samples) but operations will be much faster than computing distances", 
      "between training/testing pairs one pair at a time.", 
      "", 
      "Here are the contents of the `knn.py` file:"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "<pre><code>", 
      "import numpy as np", 
      "import pickle as pkl", 
      "", 
      "class KNN:", 
      "    def __init__(self, traindat, trainlabs, k=5):", 
      "        \"\"\"", 
      "        Creates an instance of class KNN. Stores training data", 
      "", 
      "        Arguments:", 
      "          traindat: pandas.DataFrame", 
      "          trainlabs: pandas.Series (+1/-1, currently unchecked)", 
      "", 
      "", 
      "        \"\"\"", 
      "        self.features = traindat.columns", 
      "        self.traindat = traindat.values", 
      "        self.trainlabs = trainlabs.values", 
      "        self.k = k", 
      "", 
      "    def __str__(self):", 
      "        return ('A %d-nn classifier on features ' % self.k) + str(self.features)", 
      "", 
      "", 
      "    def classify(self, testdat, k=None):", 
      "        \"\"\"", 
      "        Classify a set of samples", 
      "", 
      "        Arguments:", 
      "          testdat: pandas.DataFrame", 
      "          k: None, integer, or integer list of ascending k values", 
      "", 
      "        Returns:", 
      "          matrix of (+1/-1) labels (if k is a list)", 
      "          list of labels, if k is integer", 
      "", 
      "        \"\"\"", 
      "        testdat = testdat.values", 
      "        ntest_samples = testdat.shape[0]", 
      "", 
      "        if k is None:", 
      "            k = self.k", 
      "", 
      "        # check if k is an integer, if so wrap into list", 
      "        try:", 
      "            len(k)", 
      "        except TypeError:", 
      "            k = [k]", 
      "", 
      "        # compute cross-products of training and testing samples", 
      "        xy = self.traindat.dot(testdat.T)", 
      "", 
      "        # compute norms", 
      "        xx = np.sum(self.traindat * self.traindat, 1)", 
      "        yy = np.sum(testdat * testdat, 1)", 
      "", 
      "        # now iterate over testing samples", 
      "        out = np.empty((ntest_samples, len(k)))", 
      "        for i in range(ntest_samples):", 
      "            # compute distance to all training samples", 
      "            dists = np.sqrt(xx - 2*xy[:,i] + yy[i])", 
      "", 
      "            # find the indexes that sort the distances", 
      "            sorted_indexes = np.argsort(dists)", 
      "", 
      "            # now iterate over k-values to compute labels", 
      "            thesum = 0", 
      "            start = 0", 
      "            for j in range(len(k)):", 
      "                cur_k = k[j]", 
      "", 
      "                # add votes up to the current k value", 
      "                for l in range(start, cur_k):", 
      "                    thesum = thesum + self.trainlabs[sorted_indexes[l]]", 
      "", 
      "                # tally the votes", 
      "                out[i,j] = np.sign(thesum)", 
      "                start = cur_k", 
      "", 
      "        # massage the output if only one k was used", 
      "        if len(k) == 1:", 
      "            out = out.reshape(ntest_samples)", 
      "", 
      "        return out", 
      "", 
      "    def tune(self, tunedat, tunelabs, k=range(1,12,2)):", 
      "        \"\"\"", 
      "        Tune a k-nn classifier", 
      "", 
      "        Arguments:", 
      "          tunedat: pandas.DataFrame a tuning set", 
      "          tunelabs: pandas.Series labels for tuning set", 
      "          k: a list of increasing integer k values", 
      "", 
      "        Returns:", 
      "          Nothing", 
      "", 
      "        Side effect:", 
      "          sets self.k to the value of k that minimizes error on the tuning set", 
      "          sets self.tuning_k to the set of k values tested", 
      "          sets self.tuning_err to the tuning set error for each of the k values", 
      "", 
      "        \"\"\"", 
      "        tunelabs = tunelabs.values", 
      "        ntune_samples = tunedat.shape[0]", 
      "", 
      "        self.tuning_k = k", 
      "        self.tuning_err = np.empty(len(self.tuning_k))", 
      "        predlabs = self.classify(tunedat, self.tuning_k)", 
      "", 
      "", 
      "        for i in range(len(k)):", 
      "            self.tuning_err[i] = np.mean((tunelabs * predlabs[:,i]) < 0)", 
      "", 
      "        self.k = k[np.argmin(self.tuning_err)]", 
      "", 
      "    def dump(self, file):", 
      "        \"\"\"", 
      "        Store k-nn classifier object to file", 
      "", 
      "        \"\"\"", 
      "        try:", 
      "            fp = open(file,'wb')", 
      "            pkl.dump(self, fp)", 
      "            fp.close()", 
      "        except Exception as e:", 
      "            'Pickling failed for object ' + str(self) + ' on file ' + file + ' Exception: ' + e.message", 
      "", 
      "def load(file):", 
      "    \"\"\"", 
      "    Load k-nn classifier object from file", 
      "", 
      "    \"\"\"", 
      "    try:", 
      "        fp = open(file,'rb')", 
      "    except IOError as e:", 
      "        'Pickling knn failed error({0}): {1}'.format(e.errno, e.strerror)", 
      "        return None", 
      "", 
      "    try:", 
      "        obj = pkl.load(fp)", 
      "    except AttributeError as e:", 
      "        print ('Pickling knn failed for file ' + file + ' ' + str(e))", 
      "        fp.close()", 
      "        return None", 
      "    except pkl.UnpicklingError as e:", 
      "        print str(e)", 
      "        fp.close()", 
      "        return None", 
      "", 
      "    fp.close()", 
      "    return obj", 
      "</code></pre>"
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "####A note about using the IPython notebook. ", 
      "", 
      "You'll notice that we separated method code (e.g., file `knn.py`) from the notebook", 
      "executable code. The goal is to make that code usable in other contexts, and you should develop it as a python module. However,", 
      "below we will report on the performance of this classifer, and we want the notebook to reflect the code as closely as possible. So,", 
      "my suggestion as to how to do this. Once you have developed your method code and run your experiments to your satisfaction,", 
      "before you start the analysis of your results in the IPython notebook you can add code to the notebook (but not as executable code) using", 
      "the following steps:", 
      "", 
      "1. Insert a new code cell to the notebook at the point where you want to insert code", 
      "2. Type into the cell and execute the command `%loadpy somefile.py`. This will create a new cell with the code in `somefile.py`", 
      "3. Turn the new cell into a markdown cell (use the menu on the left panel, or the `ctl-M M` keyboard shortcut) ", 
      "4. Wrap the code in html tags `<pre><code> ... </code></code>`", 
      "", 
      "This is how I inserted the code above."
     ]
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "####Let's go on", 
      "", 
      "Now we can test this code on a toy dataset"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "develdat=pd.DataFrame(arange(30).reshape((6,5)))", 
      "devellabs=pd.Series([1,1,1,-1,-1,-1])", 
      "print develdat"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 74
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "from pa01 import KNN", 
      "develknn=KNN(develdat,devellabs,k=1) # J: Labels given to 1-NN so that it can train (obviously)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 77
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print 'Classifying with 1-NN'", 
      "print develknn.classify(develdat)", 
      "", 
      "print 'Classifying with 5-nn'", 
      "print develknn.classify(develdat,k=5)", 
      "", 
      "print 'Classifying with 1 and 3 NN'", 
      "print develknn.classify(develdat, k=[1,3])"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 82
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "# test the tuning function", 
      "develknn.tune(develdat.ix[0:2,],devellabs[:3],k=np.arange(1,5,2))", 
      "", 
      "print 'The k values tested'", 
      "print develknn.tuning_k", 
      "", 
      "print 'error on the tuning set, for these values'", 
      "print develknn.tuning_err"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 34
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Applying to spam data", 
      "", 
      "Now we are ready to apply the k-nn classifier to the spam data. The idea is to initialize the object, then tune and finally get an estimate", 
      "of generalization error using the test data. It is better to run this outside the IPython notebook and store results", 
      "in the output data directory. I've added a `main.py` file to the *project* directory with the following code:"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import numpy as np", 
      "import pandas as pd", 
      "from pa01 import KNN, load", 
      "", 
      "", 
      "def main():", 
      "    print 'Loading data'", 
      "    spam_train = pd.load(../'proc_data/training_data/spam_train.pdat')", 
      "    spam_tune = pd.load('../proc_data/training_data/spam_tune.pdat')", 
      "", 
      "    print 'Building classifier'", 
      "    spam_knn = KNN(spam_train.ix[:,:-1], spam_train['spam'])", 
      "", 
      "    print 'Tuning classifier k is 1 to 41 by 2'", 
      "    spam_knn.tune(spam_tune.ix[:,:-1], spam_tune['spam'], k=range(1,42,2))", 
      "", 
      "    print 'Loading test data'", 
      "    spam_test = pd.load('../proc_data/testing_data/spam_test.pdat')", 
      "", 
      "    print 'Classifying test data'", 
      "    predlabs = spam_knn.classify(spam_test.ix[:,:-1])", 
      "", 
      "    print 'Saving output objects'", 
      "    spam_knn.dump('../output_data/spam_knn.pyobj')", 
      "", 
      "    # store the predicted labels for the test set in text file", 
      "    np.savetxt('../output_data/predlabs.txt', predlabs)", 
      "", 
      "    obj=load('../output_data/spam_knn.pyobj')", 
      "    print obj", 
      "", 
      "if __name__ == '__main__':", 
      "    main()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "###Analyzing results", 
      "", 
      "Now that we have run our experiment (train/tune/test the k-nn classifier on the spam data), we are ready to analyze the result. Let's answer some questions:", 
      "", 
      "What was the k chosen by the tuning method?"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# first of all we need to load the classifier", 
      "from pa01 import load", 
      "spam_knn = load('../output_data/spam_knn.pyobj')", 
      "", 
      "print 'The k chosen on the tuning set was %d' % spam_knn.k"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 87
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "What was the effect of $k$ on generalization error?"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# let's plot it", 
      "plt.figure()", 
      "plt.plot(spam_knn.tuning_k, spam_knn.tuning_err)", 
      "plt.title(\"Tuning error vs. k\")", 
      "plt.show()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 88
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "So, the smallest generalization error was 0.18 and was achieved by k=1 as we saw before.", 
      "", 
      "What is the error on the test set?"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# first let's load the test set", 
      "spam_test = pd.load('../proc_data/testing_data/spam_test.pdat')", 
      "test_labels = spam_test['spam'].values", 
      "", 
      "# now let's read the predicted labels which we stored in main.py", 
      "pred_labels = np.genfromtxt('../output_data/predlabs.txt')", 
      "", 
      "# and compute error rate", 
      "test_error = np.mean ( (pred_labels * test_labels) < 0)", 
      "", 
      "print 'Error on the test set for knn was %0.4f' % test_error", 
      "                        "
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Well, there we go. Not very good, let's see if you can improve in your programming project."
     ]
    }
   ]
  }
 ]
}